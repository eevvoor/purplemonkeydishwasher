<!DOCTYPE html><html>
<head>
<title>Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html</title>
<!--Generated on Fri Sep 29 13:03:26 2017 by LaTeXML (version 0.8.2) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Last modified: September 29, 2017.-->

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../latexml/LaTeXML.css" type="text/css">
<link rel="stylesheet" href="../latexml/ltx-article.css" type="text/css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Effect of Language and Error Models on Efficiency of Finite-State
Spell-Checking and Correction<span class="ltx_ERROR undefined">\footnotepubrights</span>Originally published in
FSMNLP 2012 in Donostia. Official version available from ACL anthology:
<span class="ltx_ERROR undefined">\url</span>http://aclweb.org/anthology//sigfsm.html</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Tommi A Pirinen
<br class="ltx_break">University of Helsinki
<br class="ltx_break">Department of Modern Languages
<br class="ltx_break">FI-00014 Univ. of Helsinki
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> PO box 24
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">tommi.pirinen@helsinki.fi</span>
<br class="ltx_break">Sam Hardwick
<br class="ltx_break">University of Helsinki
<br class="ltx_break">Department of Modern Languages
<br class="ltx_break">FI-00014 Univ. of Helsinki
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> PO box 24
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">sam.hardwick@helsinki.fi</span>
<br class="ltx_break">
</span></span>
</div>
<div class="ltx_date ltx_role_creation">Last modified: September 29, 2017</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>

<p class="ltx_p">We inspect the viability of finite-state
spell-checking and contextless correction of non-word errors in morphologically
different languages. Overviewing previous
work, we conduct large-scale tests involving three languages
— covering a broad spectrum of morphological features;
English, Finnish and Greenlandic — and a variety of
error models and algorithms, including proposed
improvements of our own. Special reference is made to on-line
three-way composition of the input, the error model and the language model.
Tests are run on real-world text acquired from
freely available sources.
We show that the finite-state approaches discussed are sufficiently fast
for high-quality correction, even for Greenlandic which, due to its morphological
complexity, is a difficult task for non-finite-state approaches.</p>

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">In most applications of spell-checking, efficiency is a limiting
factor for selecting or discarding spell-checking solutions. In the case of
finite-state spell-checking it is known that finite-state language models can
efficiently encode dictionaries of natural languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="Finite state morphology" class="ltx_ref">1</a>]</cite>, even
for polysynthetic languages. The efficiency of finite-state approaches to
spelling correction, however, has often been seen as a problem, and therefore
most contemporary spell-checking and correction systems are still based on
programmatic solutions (e.g. hunspell<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_ERROR undefined">\url</span>http://hunspell.sf.net</span></span></span>,
and its *spell relatives), or at most specialised algorithms for implementing
error-tolerant traversal of the finite-state
dictionaries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction" class="ltx_ref">15</a>, <a href="#bib.bib22" title="Fast approximate string matching with finite automata" class="ltx_ref">6</a>]</cite>. There have also been few fully
finite-state implementations for both the detecting and correcting
errors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="Fast string correction with levenshtein-automata" class="ltx_ref">21</a>, <a href="#bib.bib67" title="Finite-state spell-checking with weighted language and error models" class="ltx_ref">16</a>]</cite>. In this paper we further evaluate
the use of finite-state dictionaries with two-tape finite-state automatons for
mechanism to correct misspellings, and how to optimise the finite-state error
models.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">To evaluate the general usability and efficiency of finite-state spell-checking
we test the system with three languages of typologically different
morphological features<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>we will not go deep into detail of morphological
features of these languages. We thank the anonymous reviewer for pointing us
to make this rough comparison using translated text piece. We measure from the translations of the
<em class="ltx_emph">Universal Declaration of Human Rights</em> (with pre-amble included) thusly:
the number of word-like tokens for English is 1,746, for Finnish 1,275 and forÂ§
Greenlandic 1,063. The count of 15 most frequent tokens are for English
120—28,
for Finnish 85—10 and for Greenlandic 38—7.
The average word length is 5.0 for English, 7.8 for Finnish and 14.9 for
Greenlandic. For complexity of computational models refer to the
Table <a href="#S3.T2" title="Table 2 ‣ 3 Material ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> in this article.
</span></span></span> and <em class="ltx_emph">different reference implementations for
contemporary spell-checking applications</em>: English as a sample of a
morphologically more isolating language with a basically word-list approach to
spell-checking; as a reference implementation we use hunspell’s en-US
dictionary<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_ERROR undefined">\url</span>http://wiki.services.openoffice.org/wiki/Dictionaries</span></span></span>
and for a finite-state version we use a weighted word-list from
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="How to write a spelling corrector" class="ltx_ref">14</a>]</cite>. The second language we test is Finnish, whose
computational complexity has been just beyond the edge of being too hard to
implement nicely in hunspell system for example <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="Hunspell-in kesäkoodi 2006: final report" class="ltx_ref">19</a>]</cite>. For a
reference implementation we use Voikko<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_ERROR undefined">\url</span>http://voikko.sf.net</span></span></span>,
with a LAG-based dictionary using
Malaga<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_ERROR undefined">\url</span>http://home.arcor.de/bjoern-beutel/malaga/</span></span></span>. Our third
test language is Greenlandic, a polysynthetic language which is implemented as
finite-state system using Xerox’s original finite-state morphology
formalism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="Finite state morphology" class="ltx_ref">1</a>]</cite>. We use Foma <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="Foma: a finite-state compiler and library" class="ltx_ref">7</a>]</cite> for performing the
correction task<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_ERROR undefined">\url</span>http://code.google.com/p/Foma/</span></span></span>. As a general
purpose finite-state library we use HFST<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_ERROR undefined">\url</span>http://hfst.sf.net</span></span></span>,
which also provides our spell-checking code. There is no free software for us
as a reference implementation apart from our solution, as far as we know.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">The baseline feature set and the efficiency of spell-checking we are targeting
is defined by the currently de facto standard spelling suite in open source
systems, hunspell. As neither Finnish nor Greenlandic have been successfully
implemented in the hunspell formalism, we mainly use them to evaluate how
the complexity of a language model affects the efficiency of finite-state
spell-checking. For a full-scale survey on the state-of-the-art
non-finite-state spell-checking, refer to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="Ordering the suggestions of a spellchecker without using context*" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">The efficiency results are contrasted with the existing research on
finite-state spell-checking in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="Language independent text correction using finite state automata" class="ltx_ref">5</a>]</cite> and the theoretical
results on finite-state error-models in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="Universal levenshtein automata. building and properties" class="ltx_ref">12</a>]</cite>. Our addition
primarily comprises the addition of morphologically complex languages with
actual cyclic dictionary automata (i.e. infinite dictionaries formed by
compounding and recurring derivation) and more complex structure in general,
compared to those of English and Arabic. We also point out that previous
approaches have neglected to simultaneously constrain the error model and the
dictionary with each other in on-line composition, which affords a significant
speed benefit compared to generating the two component compositions.
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">The rest of the paper is organised as follows. In Section <a href="#S2" title="2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we
discuss the spell-checking task, current non-finite-state spell-checkers and
previously used finite-state methods for spell-checking and correction and
propose some possible speed optimisations for the error models.
We also investigate algorithmic limitations of finite-state approaches and
ways to remedy them. In
Section <a href="#S3" title="3 Material ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> we present the language models, error models and the
testing corpora. In Section <a href="#S4" title="4 Evaluation ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> we
present the comparisons of speed and quality with combinations of different
language and error models and corpora for spell-checking. In
Section <a href="#S5" title="5 Conclusions And Future Work ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we summarise our findings and results,
and outline future goals.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">A finite-state spell-checker is typically composed of at least two finite-state
automata; one for the dictionary of the language, or the <em class="ltx_emph">language model</em>,
which contains valid strings of the language, and one automaton to map misspelt
words into correct strings, or the <em class="ltx_emph">error model</em>. Both the language models
and the error models are usually weighted finite-state automata, in which
case the probabilities are of a word being correctly spelled in the language
model and of specific misspellings, respectively.
We evaluate here the effect of both the language and error model automatons’
structure and complexity on the efficiency of the finite-state
spelling task.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup>The methods introduced in this research
as well as all materials are free/libre open source. Please see our svn
repository <span class="ltx_ERROR undefined">\url</span>https://hfst.svn.sf.net/svnroot/trunk/fsmnlp-2012-spellers/
for detailed implementation and scripts to reproduce all the
results.</span></span></span></p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Language Models</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p">The most basic language model for a spell-checking dictionary is a list of
correctly spelled word forms. One of the easiest way to create such
spell-checker is collecting the word forms from reasonably large corpus of
(mostly) correctly spelt texts; additionally we can count the frequency of words
and use that as the likelihood <math id="S2.SS1.p1.m1" class="ltx_Math" alttext="P=\frac{c(\mathrm{wordform})}{\mathrm{Corpussize}}" display="inline"><mrow><mi>P</mi><mo>=</mo><mfrac><mrow><mi>c</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>wordform</mi><mo stretchy="false">)</mo></mrow></mrow><mi>Corpussize</mi></mfrac></mrow></math>.
For morphologically more isolating languages such as English, this is
often a sufficient
approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="How to write a spelling corrector" class="ltx_ref">14</a>]</cite>, and we use it to create a dictionary
for our English
spell-checker as well. As a non-finite-state reference point we use
hunspell.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p class="ltx_p">For agglutinative languages like Finnish, for which the word-list approach is
likely to miss much greater amount of words, one of the commonest approaches is
to use right-linear grammars, possibly combined with finite-state rule
languages to implement morphophonological alterations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="Two-level morphology: a general computational model for word-form recognition and production" class="ltx_ref">8</a>]</cite>.
This approach also applies to the newest available free open source and full
fledged finite-state Finnish morphological dictionary we
found <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="Modularisation of finnish finite-state language descriptionâtowards wide collaboration in open source development of morphological analyser" class="ltx_ref">17</a>]</cite>. This language model features productive
derivations, compounding and rudimentary probabilistic models. We take as a
reference non-finite state language model for Finnish Voikko’s implementation
in Malaga, which is currently used as a spell-checking component in open source
software. It is implemented in a left-associative grammar formalism, which is a
potentially less efficient system with more expressive power. It’s similar to
finite-state formulations in terms of linguistic coverage—the main rationale
of original implementation, however, was that it was first openly available
approach at that time.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p class="ltx_p">For polysynthetic languages it will be obvious that coverage of any
word-list-based approach will be even lower. Furthermore, most simple
extensions to it such as affix stripping (as in hunspell) are not adequate for
describing word forms. To our knowledge, the only approaches that have been
widely used for spell-checking and morphological analysis of Greenlandic have
been based on traditional finite-state solutions, such as the Xerox formalisms.
In our case we have obtained one from the Internet, that was based on freely
available finite-state morphology
implementation<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_ERROR undefined">\url</span>https://victorio.uit.no/langtech/trunk/st/kal</span></span></span>.
For further details we refer to the authors’ website
<span class="ltx_ERROR undefined">\url</span>http://oqaaserpassualeriffik.org/.
</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Error Models</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p">The ubiquitous formula for modeling typing errors since the computer-assisted
spelling correction began has been the edit distance metric sometimes
attributed to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="Binary codes capable of correcting deletions, insertions, and reversals" class="ltx_ref">10</a>]</cite> and/or <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="A technique for computer detection and correction of spelling errors" class="ltx_ref">4</a>]</cite>. It maps
four typical slips of the fingers on a keyboard to events in the fuzzy matching
of the misspelt word forms to correct ones, that is, the deletion of a
character (i.e. failing to press a key), addition of a character (i.e. hitting
an extra key accidentally), changing a character (i.e. hitting the wrong key)
and swapping adjacent characters (i.e. hitting two keys in the wrong order).</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p">When modeling edit distance as finite-state automaton, a relatively simple
two-tape automaton is sufficient to implement the algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="Language independent text correction using finite state automata" class="ltx_ref">5</a>]</cite>.
The automaton will consist of one arc for each type of error, and additionally
one state for each swapping of character type of error is needed to keep the
character pair to be swapped in memory. This means that the trivial
nondetermistic finite-state automaton implementing the algorithm is of space
complexity <math id="S2.SS2.p2.m1" class="ltx_Math" alttext="S(V,E,\Sigma)=O(|\Sigma|^{2}|V|+|\Sigma|^{2}|E|)" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>V</mi><mo>,</mo><mi>E</mi><mo>,</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>O</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><msup><mrow><mo stretchy="false">|</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">|</mo></mrow><mn>2</mn></msup><mo>⁢</mo><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></mrow><mo>+</mo><mrow><msup><mrow><mo stretchy="false">|</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">|</mo></mrow><mn>2</mn></msup><mo>⁢</mo><mrow><mo stretchy="false">|</mo><mi>E</mi><mo stretchy="false">|</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></math>, where
<math id="S2.SS2.p2.m2" class="ltx_Math" alttext="\Sigma" display="inline"><mi mathvariant="normal">Σ</mi></math> is the alphabet of language, <math id="S2.SS2.p2.m3" class="ltx_Math" alttext="V" display="inline"><mi>V</mi></math> is the set vertices in automaton and
<math id="S2.SS2.p2.m4" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math> is the set of edges in automaton. This edit distance formulation is
roughly feature equivalent to hunspell’s <span class="ltx_text ltx_font_typewriter">TRY</span> mechanism.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p class="ltx_p">To further fine-tune this finite-state formulation of edit distance algorithm,
it is possible to attach a probability to each of the error events as a weight
in weighted finite-state automaton, which corresponds the likelihood of an
error, or a confusion factor. This can be used to implement features like
keyboard adjacency or OCR confusion factor to the error correction model. This
will not modify the structure of the finite-state error models or the search
space—which is why we did not test in this article—, but introduction of
non-homogenous weights to resulting finite-state network may have an effect on
search time. This addition is equivalent to hunspell’s <span class="ltx_text ltx_font_typewriter">KEY</span> mechanism.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p class="ltx_p">For English language spelling correction there is also an additional form of
error model to deal with competence related misspellings, as opposed to these
other models that mainly deal with mistypings, implemented in form of phonemic
folding and unfolding. This type of error is very specific to certain type of
English texts and is not dealt with in scope of this experiment. This is
the <span class="ltx_text ltx_font_typewriter">PHON</span> part of the hunspell’s correction mechanism.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p class="ltx_p">After fine-tuning the error models to reimplement hunspell’s feature set, we
propose variations of this edit distance scheme to optimise the
speed of error correction with little or no negative effect to the quality of
the correction suggestions. The time requirement of the
finite-state spelling correction algorithm is determined by the size of the
search space,
i.e. the complexity of resulting network when the error model is applied to the
misspelt string and intersected with the dictionary<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup>For non-finite-state
solutions, the search space is simply the number of
possible strings given the error corrections made in the algorithm. For
finite-state systems the amount of generated strings with cyclic language and
error models is infinite, so complexity calculation are theoretically slightly
more complex, however for basic edit distance implementations used in this
article the search space complexities are always the same and the amount of
suggestions generated finite</span></span></span>.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p class="ltx_p">To optimise the application of edit distance by limiting the search space, many
traditional spell checkers will not attempt to correct the very first letter of
the word form. We investigated whether this decision is a particularly
effective way to limit the search space, but it does not appear to
significantly differ from restricting edits at any other position in the input.</p>
</div>
<div id="S2.SS2.p7" class="ltx_para">
<p class="ltx_p">Dividing the states of a dictionary automaton into classes corresponding to
the minimum number of input symbols consumed by that state, we found that
the average ambiguity in a particular class is somewhat higher for the first
input symbols, but then stabilises quickly. This was accomplished by
performing the following
state-categorisation procedure:</p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<ol id="I1" class="ltx_enumerate">
<li id="I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">1.</span>
<div id="I1.i1.p1" class="ltx_para">
<p class="ltx_p">The start state is assigned to class <math id="I1.i1.p1.m1" class="ltx_Math" alttext="0" display="inline"><mn>0</mn></math>,
and all other states are
assigned to a candidate pool.</p>
</div>
</li>
<li id="I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">2.</span>
<div id="I1.i2.p1" class="ltx_para">
<p class="ltx_p">All states to which there is an (input)
epsilon transition from the start state are assigned to class <math id="I1.i2.p1.m1" class="ltx_Math" alttext="0" display="inline"><mn>0</mn></math> and
removed from the candidate pool.</p>
</div>
</li>
<li id="I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">3.</span>
<div id="I1.i3.p1" class="ltx_para">
<p class="ltx_p">This is repeated for each state in
class <math id="I1.i3.p1.m1" class="ltx_Math" alttext="0" display="inline"><mn>0</mn></math> until no more states
are added to class <math id="I1.i3.p1.m2" class="ltx_Math" alttext="0" display="inline"><mn>0</mn></math>. This completes class <math id="I1.i3.p1.m3" class="ltx_Math" alttext="0" display="inline"><mn>0</mn></math> as the set of states in which
the automaton can be before consuming any input.</p>
</div>
</li>
<li id="I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">4.</span>
<div id="I1.i4.p1" class="ltx_para">
<p class="ltx_p">For each state in class <math id="I1.i4.p1.m1" class="ltx_Math" alttext="0" display="inline"><mn>0</mn></math>, states in the candidate pool to which there
is a non-epsilon transition are assigned to class <math id="I1.i4.p1.m2" class="ltx_Math" alttext="1" display="inline"><mn>1</mn></math> and removed from the
candidate pool.</p>
</div>
</li>
<li id="I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">5.</span>
<div id="I1.i5.p1" class="ltx_para">
<p class="ltx_p">Class <math id="I1.i5.p1.m1" class="ltx_Math" alttext="1" display="inline"><mn>1</mn></math> is epsilon-completed as in (2-3).</p>
</div>
</li>
<li id="I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_enumerate">6.</span>
<div id="I1.i6.p1" class="ltx_para">
<p class="ltx_p">After the completion of class <math id="I1.i6.p1.m1" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math>, class <math id="I1.i6.p1.m2" class="ltx_Math" alttext="n+1" display="inline"><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></math> is constructed. This
continues until the candidate pool is empty, which will happen
as long as there are no unreachable states.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS2.p9" class="ltx_para">
<p class="ltx_p">Having this categorisation, we tallied the total number of arcs from states in
each class and divided this total by the number of states in the class. This
is intended as an approximate measure of the ambiguity present at a particular
point in the input. Some results are summarized in
table <a href="#S2.T1" title="Table 1 ‣ 2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Class</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Transitions</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">States</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Average</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">0</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">156</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">3</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">52</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">1</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1,015</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">109</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">9.3</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">6,439</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1,029</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">6.3</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">3</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">22,436</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">5,780</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3.9</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">4</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">38,899</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">12,785</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3.0</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">5</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">44,973</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">15,481</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">2.9</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">6</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">47,808</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">17,014</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">2.8</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">7</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">47,495</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">18,866</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">2.5</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">8</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">39,835</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">17,000</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">2.3</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">9</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">36,786</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">14,304</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">2.6</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">10</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">45,092</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">14,633</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3.1</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">11</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">66,598</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">22,007</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3.0</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">12</span></th>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">86,206</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">30,017</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:70%;">2.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>
State classification by minimum input consumed for the Finnish dictionary</figcaption>
</figure>
<div id="S2.SS2.p10" class="ltx_para">
<p class="ltx_p">Further, the size of a dictionary automaton that is restricted to have
a particular symbol in a particular position does not apparently depend on the
choice of position. This result was acquired by intersecting eg. the automaton
<span class="ltx_text ltx_font_typewriter">e.+</span> with the dictionary to restrict the first
position to have the symbol
<span class="ltx_text ltx_font_typewriter">e</span>, the automaton
<span class="ltx_text ltx_font_typewriter">.e.+</span> to restrict the second position, and so on.
The sizes of the transducers acquired by this intersection vary in size of the
language, number of states and number of transitions, but without any trend
according to the position of the restriction.
This is in line with the rather obvious finding that the
size of the restricted dictionary in terms of number of strings is similarily
position-agnostic.</p>
</div>
<div id="S2.SS2.p11" class="ltx_para">
<p class="ltx_p">Presumably, the rationale is a belief that errors predominately occur at other
positions in the input. As far as we know, the complete justification for this
belief remains to be made with a high-quality, hand-checked error corpus.</p>
</div>
<div id="S2.SS2.p12" class="ltx_para">
<p class="ltx_p">On the error model side this optimisation has been justified by findings where
between 1.5 % and 15 % of spelling-errors happen in the first character of
the word, depending on the text type <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="Spelling error pattern analysis of punjabi typed text" class="ltx_ref">2</a>]</cite>;
the 1.5 % from small corpus of academic texts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="An intelligent spelling error corrector" class="ltx_ref">22</a>]</cite>
and 15 % from dictated corpora <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="Techniques for automatically correcting words in text" class="ltx_ref">9</a>]</cite>. We also performed a
rudimentary classification of the errors in the small error corpus of
333 entries from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="Improving finite-state spell-checker suggestions with part of speech n-grams" class="ltx_ref">18</a>]</cite>, and found errors at
first position in 1.2 % of the entries, furthermore we noticed that
when evenly splitting the word forms in three parts, 15 % of the errors are
in the first third of the word form, while second has 47 % and third 38 %,
which would be in favor of selecting the error model to discard initial
errors<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup>by crude classification we mean that all errors were
forced to one of the three classes at weight of one, e.g. a series of
three consecutive instances of the same letters was counted as deletion at
the first position.</span></span></span>.</p>
</div>
<div id="S2.SS2.p13" class="ltx_para">
<p class="ltx_p">A second form of optimisation that is used by many traditional spell-checking
systems as well is to apply a lower order edit distances separately before
trying higher order ones. This is based on the assumption that vast majority
of spelling errors will be of lower order. In the original
account of edit distance for spell-checking, 80 % of the spelling
errors were found to be correctable with distance 1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="Automatic spelling correction in scientific and scholarly text" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="S2.SS2.p14" class="ltx_para">
<p class="ltx_p">The third form of optimisation that we test is an attempt to decrease the
number of redundant corrections in error models of higher order edit distances
than one. This means that things like adding and deleting the
same character in successive moves will not be performed. This makes the error
model more complicated but reduces the search space, and does not affect the
quality of results.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Algorithms</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p">The obvious baseline algorithm for the task of finding which strings can be
altered by the error model in such a way that the alteration is present in the
language model is generating all the possible alterations and checking which
ones are present in the language model. This was done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="Language independent text correction using finite state automata" class="ltx_ref">5</a>]</cite>
by first calculating the composition of the input string with the error
model and then composing the result with the language model.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p class="ltx_p">If we simplify the error model to one in which only substitutions occur, it can
already be seen that this method is quite sensitive to input length and
alphabet size. The composition explores each combination of edit sites in the
input string. If any number of edits up to <math id="S2.SS3.p2.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> can be made at positions in an
input string of length <math id="S2.SS3.p2.m2" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math>, there are</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1" class="ltx_Math" alttext="\sum_{i=1}^{d}{n\choose i}" display="block"><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mrow><mo>(</mo><mfrac linethickness="0pt"><mi>n</mi><mi>i</mi></mfrac><mo>)</mo></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">ways to choose the edit site, and each site is subject to a choice of
<math id="S2.SS3.p2.m3" class="ltx_Math" alttext="|\Sigma|-1" display="inline"><mrow><mrow><mo stretchy="false">|</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">|</mo></mrow><mo>-</mo><mn>1</mn></mrow></math> edits (the
entire alphabet except for the actual input). This expression has no closed
form, but as <math id="S2.SS3.p2.m4" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> grows to <math id="S2.SS3.p2.m5" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math>, the number of choices has the form <math id="S2.SS3.p2.m6" class="ltx_Math" alttext="2^{n}" display="inline"><msup><mn>2</mn><mi>n</mi></msup></math>,
so the altogether complexity is exponential in input length and linear
in alphabet size (quadratic if swaps are considered).</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p class="ltx_p">In practice
(when <math id="S2.SS3.p3.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> is small relative to <math id="S2.SS3.p3.m2" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math>) it is useful to observe that an
increase of <math id="S2.SS3.p3.m3" class="ltx_Math" alttext="1" display="inline"><mn>1</mn></math> in distance results
in an additional term to the aforementioned sum,
the ratio of which to the previously greatest term is</p>
<table id="S2.Ex2" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex2.m1" class="ltx_Math" alttext="\frac{n!/(d!\cdot(n-d!))}{n!/((d-1)!\cdot(n-d+1)!)}=\frac{n-d+1}{d}" display="block"><mrow><mfrac><mrow><mrow><mi>n</mi><mo lspace="0pt" rspace="3.5pt">!</mo></mrow><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>d</mi><mo lspace="0pt" rspace="3.5pt">!</mo></mrow><mo>⋅</mo><mrow><mo stretchy="false">(</mo><mrow><mi>n</mi><mo>-</mo><mrow><mi>d</mi><mo lspace="0pt" rspace="3.5pt">!</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mrow><mi>n</mi><mo lspace="0pt" rspace="3.5pt">!</mo></mrow><mo>/</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mrow><mo stretchy="false">(</mo><mrow><mi>d</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0pt" rspace="3.5pt">!</mo></mrow><mo>⋅</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>n</mi><mo>-</mo><mi>d</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0pt" rspace="3.5pt">!</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><mrow><mi>n</mi><mo>-</mo><mi>d</mi></mrow><mo>+</mo><mn>1</mn></mrow><mi>d</mi></mfrac></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">indicating that when <math id="S2.SS3.p3.m4" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> is small, increases in it produce an
exponential increase in complexity.
For an English 26-letter lowercase alphabet, swap
distance <math id="S2.SS3.p3.m5" class="ltx_Math" alttext="2" display="inline"><mn>2</mn></math> and the <math id="S2.SS3.p3.m6" class="ltx_Math" alttext="8" display="inline"><mn>8</mn></math>-letter word “spelling”, <math id="S2.SS3.p3.m7" class="ltx_Math" alttext="700" display="inline"><mn>700</mn></math> strings are
stored in a transducer. With transpositions, deletions, insertions and edit
weights this grows to <math id="S2.SS3.p3.m8" class="ltx_Math" alttext="100,215" display="inline"><mrow><mn>100</mn><mo>,</mo><mn>215</mn></mrow></math> different combinations of output and weight. We
have implemented this algorithm for our results by generating the edited
strings by lookup, and performing another lookup with the language model on
these strings.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p class="ltx_p">Plainly, it would be desirable to improve on this. The intuition behind our
improvement is that when editing an input string, say “spellling”, it is a
wasted effort to explore the remainder after generating a prefix that is not
present in the lexicon. For example, after changing the first character to “z”
and not editing the second characted, we have the prefix “zp-”, which does
not occur in our English lexicon. So the remaining possibilities - performing
any remaining edits on the remaining <math id="S2.SS3.p4.m1" class="ltx_Math" alttext="7" display="inline"><mn>7</mn></math>-character word - can be ignored.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p class="ltx_p">This is accomplished with a three-way composition, in which the input, the
error model and the language model simultaneously constrain each other to
produce the legal correction set. This algorithm is presented in some detail
in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="Using hfst for creating computational linguistic applications" class="ltx_ref">11</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Material</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">For language models we have acquired suitable free-to-use
dictionaries for three languages with a great degree of
typological variation between them. The dictionaries
are readily obtainable on the Internet.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">For error models we have created new implementations of the algorithms
to create and modify finite-state error models. For a baseline we have created
the basic edit distance error models by hand and then modified them
automatically to test different variants.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">To test the effect of correctness of the source text to speed of
spelling-checker we have retrieved of largest freely available open source text
materials from the internet, i.e. Wikipedia. The Wikipedia text as itself is
an appropriate real-world material as it contains a wide variety of spelling
errors. For material with more errors, we have used a simple script to
introduce the (further) errors at uniform probability of 1/33 per character;
using this method we can also obtain a corpus of errors with correct
corrections along them. Finally we have used a text corpus from language
different than the one being spelled to ensure that majority of words are not
in vocabulary and not fixable by standard error models.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p class="ltx_p">The corpora statistics are provided here for verification and reproducability:
the English Wikipedia
dump<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_ERROR undefined">\url</span>http://dumps.wikimedia.org/enwiki/20120211/enwiki-20120211-pages-articles.xml.bz2</span></span></span>
is 34 GiB, the Finnish
Wikipedia<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_ERROR undefined">\url</span>http://dumps.wikimedia.org/fiwiki/20120213/fiwiki-20120213-pages-articles.xml.bz2</span></span></span>
is 1 GiB, and the Greenlandic
Wikipedia<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_ERROR undefined">\url</span>http://dumps.wikimedia.org/klwiki/20120214/klwiki-20120214-pages-articles.xml.bz2</span></span></span>
is only 7 MiB. From these we have extracted the contents of the articles and
picked 100,000 first word tokens for evaluation purposes.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p class="ltx_p">In Table <a href="#S3.T2" title="Table 2 ‣ 3 Material ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we summarize the sizes of automata in
terms of structural elements. On the first row, we give the effective size of
alphabet needed to represent the whole dictionary, this is all the Unicode
code points that have been used in the dictionary, including alphabets,
punctuation and spaces. Next we give the sizes of automata as nodes and
arcs of the finite-state automaton encoding the dictionary. Finally we give the
size of the automaton as serialised on the hard disk. While this is not the
same amount of memory as its loaded data structures, it gives some indication
of memory usage of the automaton in running program. As can be clearly
seen from the table, the morphologically less isolating languages have quite
directly more in all of structural elements of automaton.
</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Automaton</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">En</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Fi</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Kl</span></th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<math id="S3.T2.m1" class="ltx_Math" alttext="\Sigma" display="inline"><mi mathsize="70%" mathvariant="normal">Σ</mi></math><span class="ltx_text" style="font-size:70%;"> set size</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text" style="font-size:70%;">43</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text" style="font-size:70%;">117</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">133</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Dictionary FSM nodes</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">49,778</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">286,719</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">628,177</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Dictionary FSM arcs</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">86,523</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">783,461</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">11,596,911</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Dictionary FSM on disk</span></th>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">2.3 MiB</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">43 MiB</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:70%;">290 MiB</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>
The sizes of dictionaries as automata</figcaption>
</figure>
<div id="S3.p6" class="ltx_para">
<p class="ltx_p">In the Table <a href="#S3.T3" title="Table 3 ‣ 3 Material ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> we give the same figures for the
sizes of error models we’ve generated. The sigma set size row here shows the
amount of alphabets left, when we have removed the parts of alphabet from the
error models that is usually not considered to be part of spell-checking
mechanism, such as all punctuation that does not occur word-internally and
white-space characters<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup>The method described here does not handle
run-on words or extraneous spaces, as they introduce lot of programmatic
complexity which we believe is irrelevant to the results of this experiment.</span></span></span>.
Note, that sizes of error models can be directly computed from its parameters;
i.e., the distance, the <math id="S3.p6.m1" class="ltx_Math" alttext="\Sigma" display="inline"><mi mathvariant="normal">Σ</mi></math> set size and the optimisation, this table
is provided for reference only.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Automaton</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">En</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Fi</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Kl</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<math id="S3.T3.m1" class="ltx_Math" alttext="\Sigma" display="inline"><mi mathsize="70%" mathvariant="normal">Σ</mi></math><span class="ltx_text" style="font-size:70%;"> set size</span>
</td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">28</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">60</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">64</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 1 nodes</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">652</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">3,308</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3,784</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 1 arcs</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">2,081</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">10,209</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">11,657</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 2 nodes</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1,303</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">6,615</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">7,567</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 2 arcs</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">4136</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">20,360</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">23,252</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 1 nodes</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">652</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">3,308</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3,784</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 1 arcs</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">2,107</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">10,267</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">11,719</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 2 nodes</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1,303</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">6,615</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">7,567</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 2 arcs</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">4,162</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">20,418</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">23,314</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No redundancy and 1.s ed 2 nodes</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1,303</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">6,615</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">7,567</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No redundancy and 1.s ed 2 arcs</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">4,162</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">20,418</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">23,314</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Lower order first ed 1 to 2 arcs</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">6,217</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">30,569</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">34,909</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Lower order first ed 1 to 2 nodes</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">1,955</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">9,923</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:70%;">11,351</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>
The sizes of error models as automata</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">The evaluations in this section are performed on quad-core Intel Xeon E5450
running at 3 GHz with 64 GiB of RAM memory. The times are averaged over five
test runs of 10,000 words in a stable server environment with no server processes
or running graphical interfaces or other uses. The test results are measured using the
<span class="ltx_text ltx_font_typewriter">getrusage</span> C function on a system that supports the maximum resident
stack size <span class="ltx_text ltx_font_typewriter">ru_maxrss</span> and user time <span class="ltx_text ltx_font_typewriter">ru_utime</span> fields. The
times are also verified with GNU <span class="ltx_text ltx_font_typewriter">time</span> command. The results for
hunspell, Voikkospell and Foma processes are only measured with time and top.
The respective versions of the software are Voikkospell 3.3, hunspell
1.2.14, and Foma 0.9.16alpha. The reference systems are tested with default
settings, this means that they will give some first suggestions whereas
our system will calculate all strings within given error model.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">In the Table <a href="#S4.T4" title="Table 4 ‣ 4 Evaluation ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> we measure the speed of
the spell-checking process of the native language Wikipedia with real-world
spelling errors and unknown strings. The error model rows are defined as
follows: on the <em class="ltx_emph">Reference impl.</em> row, we test the spell-checking speed of
the hunspell tool for English, and Voikkospell tool for Finnish. On the
<em class="ltx_emph">edit distance 2</em> row we use the basic traditional edit distance 2 without
any modifications. On the row <em class="ltx_emph">lower order first</em>, we apply a
lower order edit distance model first, then if no results are found,
a higher order model is used. On the <em class="ltx_emph">No first edits</em> row we
use the error model that may not modify the first character of the word or the
first character after compound word boundary. On the <em class="ltx_emph">Avoid redundancy</em>
row we use the error model edit distance 2 with the redundant edit combinations
removed. On the <em class="ltx_emph">Avoid redundancy and first edits</em> rows we use combined
error model of <em class="ltx_emph">No first edits</em> and <em class="ltx_emph">Avoid redundancy</em>
functionalities. In the tables and formulae we routinely use the language
codes to denote the languages: <em class="ltx_emph">en</em> for English, <em class="ltx_emph">fi</em> for Finnish and
<em class="ltx_emph">kl</em> for Greenlandic (Kalaallisut).</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Error model</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">En</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Fi</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Kl</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">Reference impl.</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">9.93</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">7.96</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">11.42</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Generate all edits 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">3818.20</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">118775.60</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">36432.80</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">Edit distance 1</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">0.26</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">6.78</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">4.79</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">7.55</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">220.42</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">568.36</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 1</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.44</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">3.19</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">3.52</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1.38</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">61.88</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">386.06</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No redundancy ed 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">7.52</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">4230.94</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">6420.66</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No redundancy and firsts ed 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1.51</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">62.05</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">386.63</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Lower order first ed 1 to 2</span></th>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">4.31</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">157.07</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:70%;">545.91</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span> Effect of language and
error models to speed (time in seconds per 10,000 word forms)</figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">The results show that not editing the first position does indeed give
significant boost to the speed, regardless of language model, which is of course
caused by the significant reduction in search space. However, the
redundancy avoidance does not seem to make a significant difference. This is most
likely because the amount of duplicate paths in the search space is not so
proportionally large and their traversal will be relatively fast. The separate
application of error models gives the expected timing result between its
relevant primary and secondary error models. It should be noteworthy, that, when
thinking of real world applications, the speed of the most of the models
described here is greater than 1 word per second (i.e. 10,000 seconds per 10,000
words).</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">We measured the memory
consumption when performing the same tests. Varying the error model had little
to no effect. Memory consumption was almost entirely determined by the language
model, giving consumptions of 13-7 MiB for English, 0.2 GiB for Finnish and
1.6 GiB for Greenlandic.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p class="ltx_p">The memory measurements show an interesting feature of our method of applying
the spell-checking and correction here; the memory usage stays nearly same
regardless of the selected error model. We assume that the memory figures shown
in the table are dominated by the memory stamp of the dictionary automaton and
the error model automaton loaded into memory, and the intermediate structures
used by the error-applying traversal of the automaton will not typically
contribute much (approx. half mebibyte<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup>this is a standard SI measure
unit, if unfamiliar, refer to <span class="ltx_ERROR undefined">\url</span>http://en.wikipedia.org/wiki/Mebibyte</span></span></span> for
each larger edit distance), since they are created and deleted on-the-fly.
Notable discrepancy to this pattern is Greenlandic with larger edit distances,
it seems to exhaust whole memory which may be caused an inadvertent (epsilon)
loop in the morphology. One practical thing to note here is, the memory
footstamp does give suggestion of how much available RAM is needed to get speed
measurements of the table <a href="#S4.T4" title="Table 4 ‣ 4 Evaluation ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, as our
experience shows that if the dictionary automaton is partially in swap memory,
the speed will decrease by order of magnitude in current operating systems,
e.g. on low-end minilaptops and Greenlandic dictionaries.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p class="ltx_p">To measure the degradation of quality when using different error models we
count the proportion of suggestion sets that contain the correct correction
among the corrected strings. For this test we use automatically generated corpus
of spelling errors to get the large-scale results.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Error model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">En</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Fi</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Kl</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt ltx_border_t"><span class="ltx_text" style="font-size:70%;">Edit distance 1</span></th>
<td class="ltx_td ltx_align_right ltx_border_tt ltx_border_t"><span class="ltx_text" style="font-size:70%;">0.89</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt ltx_border_t"><span class="ltx_text" style="font-size:70%;">0.83</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt ltx_border_t"><span class="ltx_text" style="font-size:70%;">0.81</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.99</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.95</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">0.92</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Edit distance 3</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">1.00</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.96</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">—</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 1</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.74</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.73</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">0.60</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.81</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">0.82</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">0.69</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">No firsts ed 3</span></th>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">0.82</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">—</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:70%;">—</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span> Effect of language and
error models to quality (recall, correct suggestion found per
correction set)</figcaption>
</figure>
<div id="S4.p7" class="ltx_para">
<p class="ltx_p">This test with automatically introduced errors shows us that with uniformly
distributed errors the penalty of changing error model to ignore the
word-initial could be significant. This contrasts to our findings with real
world errors, that the distribution of errors tends towards the end of the word,
described in <a href="#S2.SS2" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> and  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="Spelling error pattern analysis of punjabi typed text" class="ltx_ref">2</a>]</cite>,
but it should be noted that degradation can be as bad as given here.</p>
</div>
<div id="S4.p8" class="ltx_para">
<p class="ltx_p">Finally we measure how the text type used will effect the speed of the
spell-checking. As the best-case scenario we use the unmodified texts of
Wikipedia, which contain probably the most realistic native language
speaker-like typing error distribution. For text with some more errors, where
majority of errors should be recoverable we introduce more automatically
generated errors in the Wikipedia texts. Finally to see the performance on
the worst case scenario where most of the words have unrecoverable
spelling errors
we use the texts from other languages, in this case English texts for Finnish
and Greenlandic spell-checking and Finnish texts for English spell-checking,
which should bring us close to the lower bounds on performance. The
effects of text type (i.e. frequency of non-words) to speed of spell-checking
is given in table <a href="#S4.T6" title="Table 6 ‣ 4 Evaluation ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. All of
the tests in this category were performed with error models under row
<em class="ltx_emph">avoid redundancy and firsts ed 2</em> in previous tables, which gave us the
best speed/quality ratio in the previous tests.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Error model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">En</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Fi</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Kl</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">Native Lang. Corpus</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">1.38</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text" style="font-size:70%;">61.88</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:70%;">386.06</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Added automatic errors</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">6.91</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text" style="font-size:70%;">95.01</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text" style="font-size:70%;">551.81</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:70%;">Text in another language</span></th>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">22.40</span></td>
<td class="ltx_td ltx_align_right ltx_border_b"><span class="ltx_text" style="font-size:70%;">148.86</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:70%;">783.64</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span> Effect of text type on
error models to speed (in seconds per 10,000 word-forms)</figcaption>
</figure>
<div id="S4.p9" class="ltx_para">
<p class="ltx_p">Here we chiefly note that the amount of non-words in text reflects directly to
the speed of spell-checking. This shows that the dominating factor of the
speed of spell-checking is indeed in the correcting of wrong results.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions And Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">In this article, we built a full-fledged finite-state spell-checking system from
existing finite-state language models and generated error models. We showed
that using online serial composition of the word form, error model and
dictionary instead of previous approaches is usable for morphologically
complex languages. Furthermore
we showed that the error models can be automatically optimised in several ways
to gain some speed at cost of recall.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p">We showed that the memory consumption of the spell-checking process is mainly
unaffected by the selection of error model, apart from the need to store
a greater set of suggestions for models that generate more suggestions. The
error models may therefore be quite freely changed in real world
applications as needed.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p class="ltx_p">We verified that correcting only the first input letter affords a significant
speed improvement, but that this improvement is not dependent on the position
of such a restriction. This practice is somewhat supported by our tentative
finding that it may cause the least drop in practical recall figures, at least
in Finnish. It is promising especially in conjunction with a fallback model
that does correct the first letter.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p class="ltx_p">We described a way to avoid having a finite-state error model perform
redundant work, such as deleting and inserting the same letter in succession.
The practical improvement from doing this is extremely modest, and it increases
the size of the error model.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p class="ltx_p">In this research we focused on differences in automatically generated error
models and their optimisations in the case of morphologically complex languages.
For future research we intend to study more realistic error models induced from
actual error corpora (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="An improved error model for noisy channel spelling correction" class="ltx_ref">3</a>]</cite>). Research into
different ways to induce weights into the language models, as well as further use
of context in finite-state spell-checking (as in
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="Improving finite-state spell-checker suggestions with part of speech n-grams" class="ltx_ref">18</a>]</cite>), is warranted.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">We thank the anonymous reviewers for their comments and the HFST research
team for fruity discussions on the article’s topics. The first author thanks
the people of <em class="ltx_emph">Oqaaserpassualeriffik</em> for introducing the problems and
possibilities of finite-state applications to the morphologically complex
language of Greenlandic.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib40" class="ltx_bibitem ltx_bib_book">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. R. Beesley and L. Karttunen</span><span class="ltx_text ltx_bib_year"> (2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Finite state morphology</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">CSLI publications</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 978-1575864341</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S1.p2" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem ltx_bib_thesis">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Bhagat</span><span class="ltx_text ltx_bib_year"> (2007)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Spelling error pattern analysis of punjabi typed text</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Master’s Thesis</span>, <span class="ltx_text ltx_bib_publisher">Thapar University</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://hdl.handle.net/123456789/247" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p12" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>,
<a href="#S4.p7" title="4 Evaluation ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">E. Brill and R. C. Moore</span><span class="ltx_text ltx_bib_year"> (2000)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">An improved error model for noisy channel spelling correction</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">ACL ’00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Morristown, NJ, USA</span>, <span class="ltx_text ltx_bib_pages"> pp. 286–293</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://dx.doi.org/http://dx.doi.org/10.3115/1075218.1075255" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S5.p5" title="5 Conclusions And Future Work ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">F. J. Damerau</span><span class="ltx_text ltx_bib_year"> (1964)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A technique for computer detection and correction of spelling errors</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Commun. ACM</span> (<span class="ltx_text ltx_bib_number">7</span>).
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p1" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Hassan, S. Noeman and H. Hassan</span><span class="ltx_text ltx_bib_year"> (2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Language independent text correction using finite state automata</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the Third International Joint Conference on Natural Language Processing</span>,
</span>
<span class="ltx_bibblock">Vol. <span class="ltx_text ltx_bib_volume">2</span>, <span class="ltx_text ltx_bib_pages"> pp. 913–918</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.SS2.p2" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>,
<a href="#S2.SS3.p1" title="2.3 Algorithms ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>.
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Huldén</span><span class="ltx_text ltx_bib_year"> (2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Fast approximate string matching with finite automata</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Procesamiento del Lenguaje Natural</span> <span class="ltx_text ltx_bib_volume">43</span>, <span class="ltx_text ltx_bib_pages"> pp. 57–64</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Huldén</span><span class="ltx_text ltx_bib_year"> (2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Foma: a finite-state compiler and library</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics: Demonstrations Session</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">EACL ’09</span>, <span class="ltx_text ltx_bib_place">Stroudsburg, PA, USA</span>, <span class="ltx_text ltx_bib_pages"> pp. 29–32</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://dl.acm.org/citation.cfm?id=1609049.1609057" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem ltx_bib_thesis">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Koskenniemi</span><span class="ltx_text ltx_bib_year"> (1983)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Two-level morphology: a general computational model for word-form recognition and production</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Ph.D. Thesis</span>, <span class="ltx_text ltx_bib_publisher">University of Helsinki</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.ling.helsinki.fi/~koskenni/doc/Two-LevelMorphology.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.p2" title="2.1 Language Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Kukich</span><span class="ltx_text ltx_bib_year"> (1992)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Techniques for automatically correcting words in text</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">ACM Comput. Surv.</span> <span class="ltx_text ltx_bib_volume">24</span> (<span class="ltx_text ltx_bib_number">4</span>), <span class="ltx_text ltx_bib_pages"> pp. 377–439</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text issn ltx_bib_external">ISSN 0360-0300</span>,
<a href="http://dx.doi.org/http://doi.acm.org/10.1145/146370.146380" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p12" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">V. I. Levenshtein</span><span class="ltx_text ltx_bib_year"> (1966)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Binary codes capable of correcting deletions, insertions, and reversals</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Soviet Physics—Doklady 10, 707â710. Translated from Doklady Akademii Nauk SSSR</span>, <span class="ltx_text ltx_bib_pages"> pp. 845–848</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p1" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Lindén, E. Axelson, S. Drobac, S. Hardwick, Silfverberg and T. A. Pirinen</span><span class="ltx_text ltx_bib_year"> (2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Using hfst for creating computational linguistic applications</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of Computational Linguistics - Applications, 2012</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. to appear</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS3.p5" title="2.3 Algorithms ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>.
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_thesis">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. N. Mitankin</span><span class="ltx_text ltx_bib_year"> (2005)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Universal levenshtein automata. building and properties</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Master’s Thesis</span>, <span class="ltx_text ltx_bib_publisher">University of Sofia</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.fmi.uni-sofia.bg/fmi/logic/theses/mitankin-en.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Mitton</span><span class="ltx_text ltx_bib_year"> (2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Ordering the suggestions of a spellchecker without using context*</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Nat. Lang. Eng.</span> <span class="ltx_text ltx_bib_volume">15</span> (<span class="ltx_text ltx_bib_number">2</span>), <span class="ltx_text ltx_bib_pages"> pp. 173–192</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text issn ltx_bib_external">ISSN 1351-3249</span>,
<a href="http://dx.doi.org/http://dx.doi.org/10.1017/S1351324908004804" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem ltx_bib_misc">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Norvig</span><span class="ltx_text ltx_bib_year"> (2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">How to write a spelling corrector</span>.
</span>
<span class="ltx_bibblock">Note: <span class="ltx_text ltx_bib_note">referred 2011-01-11, available <span class="ltx_ERROR undefined">\url</span>http://norvig.com/spell-correct.html</span>
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://norvig.com/spell-correct.html" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.SS1.p1" title="2.1 Language Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Oflazer</span><span class="ltx_text ltx_bib_year"> (1996)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Comput. Linguist.</span> <span class="ltx_text ltx_bib_volume">22</span> (<span class="ltx_text ltx_bib_number">1</span>), <span class="ltx_text ltx_bib_pages"> pp. 73–89</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text issn ltx_bib_external">ISSN 0891-2017</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. A. Pirinen and K. Lindén</span><span class="ltx_text ltx_bib_year"> (2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Finite-state spell-checking with weighted language and error models</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the Seventh SaLTMiL workshop on creation and use of basic lexical resources for less-resourced languagages</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Valletta, Malta</span>, <span class="ltx_text ltx_bib_pages"> pp. 13–18</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://siuc01.si.ehu.es/%5C%7Ejipsagak/SALTMIL2010_Proceedings.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. A. Pirinen</span><span class="ltx_text ltx_bib_year"> (2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Modularisation of finnish finite-state language descriptionâtowards wide collaboration in open source development of morphological analyser</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of Nodalida</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">NEALT proceedings</span>, Vol. <span class="ltx_text ltx_bib_volume">18</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.helsinki.fi/%5C%7etapirine/publications/Pirinen-nodalida-2011-omorfi.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.p2" title="2.1 Language Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
</span>
</li>
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Pirinen, M. Silfverberg and K. Linden</span><span class="ltx_text ltx_bib_year"> (2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Improving finite-state spell-checker suggestions with part of speech n-grams</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Internatational Journal of Computational Linguistics and Applications â IJCLA (to appear)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p12" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>,
<a href="#S5.p5" title="5 Conclusions And Future Work ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem ltx_bib_report">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Pitkänen</span><span class="ltx_text ltx_bib_year"> (2006)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Hunspell-in kesäkoodi 2006: final report</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Technical report</span>
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.puimula.org/htp/archive/kesakoodi2006-report.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. J. Pollock and A. Zamora</span><span class="ltx_text ltx_bib_year"> (1984-04)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Automatic spelling correction in scientific and scholarly text</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Commun. ACM</span> <span class="ltx_text ltx_bib_volume">27</span> (<span class="ltx_text ltx_bib_number">4</span>), <span class="ltx_text ltx_bib_pages"> pp. 358–368</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text issn ltx_bib_external">ISSN 0001-0782</span>,
<a href="http://doi.acm.org/10.1145/358027.358048" title="" class="ltx_ref ltx_bib_external">Link</a>,
<a href="http://dx.doi.org/10.1145/358027.358048" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p13" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Schulz and S. Mihov</span><span class="ltx_text ltx_bib_year"> (2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Fast string correction with levenshtein-automata</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">International Journal of Document Analysis and Recognition</span> <span class="ltx_text ltx_bib_volume">5</span>, <span class="ltx_text ltx_bib_pages"> pp. 67–85</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem ltx_bib_article">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">E. J. Yannakoudakis and D. Fawthrop</span><span class="ltx_text ltx_bib_year"> (1983)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">An intelligent spelling error corrector</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Information Processing and Management</span> <span class="ltx_text ltx_bib_volume">19</span> (<span class="ltx_text ltx_bib_number">2</span>), <span class="ltx_text ltx_bib_pages"> pp. 101–108</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://linkinghub.elsevier.com/retrieve/pii/0306457383900468" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p12" title="2.2 Error Models ‣ 2 Methods ‣ Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction\footnotepubrightsOriginally published in FSMNLP 2012 in Donostia. Official version available from ACL anthology: \urlhttp://aclweb.org/anthology//sigfsm.html" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 29 13:03:26 2017 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>
