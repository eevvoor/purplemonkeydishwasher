<!DOCTYPE html><html>
<head>
<title>Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21. </title>
<!--Generated on Fri Sep 29 12:46:31 2017 by LaTeXML (version 0.8.2) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Last modifications: September 29, 2017.-->

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../latexml/LaTeXML.css" type="text/css">
<link rel="stylesheet" href="../latexml/ltx-article.css" type="text/css">
<link rel="stylesheet" href="../latexml/ltx-listings.css" type="text/css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Creating and Weighting Hunspell Dictionaries as Finite-State Automata
<span class="ltx_ERROR undefined">\footnotepubrights</span>This journal article was originally published in investigationes linguisticae <a href="http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21</a>.
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tommi A Pirinen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Krister Lindén
<br class="ltx_break">University of Helsinki
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Department of Modern Languages
<br class="ltx_break">Unionkatu 40
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> FI-00014 University of Helsinki
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Finland
<br class="ltx_break"><a href="%7Btommi.pirinen,krister.linden%7D@helsinki.fi" title="" class="ltx_ref ltx_url ltx_font_typewriter">{tommi.pirinen,krister.linden}@helsinki.fi</a>
<br class="ltx_break"><a href="http://www.helsinki.fi/modernlanguages" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.helsinki.fi/modernlanguages</a>
</span></span>
</div>
<div class="ltx_date ltx_role_creation">Last modifications: September 29, 2017</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>

<p class="ltx_p">There are numerous formats for writing spell-checkers for
open-source systems and there are many descriptions for languages
written in these formats. In this paper we
demonstrate a method for converting these spell-checking lexicons
into finite-state automata, and present a simple way to apply unigram
corpus training over the spell-checking suggestion mechanisms using
weighted finite-state tecnology.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>This is author’s pre-print version with hyperref turned on among other
changes, it may differ from the printed version found in Investigationes
Linguisticæ.</span></span></span></p>

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Currently there is a wide range of different free open-source
solutions for spell-checking by computer. The most popular of the spelling
dictionaries are the various instances of *spell software, i.e.
ispell<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><a href="http://www.lasr.cs.ucla.edu/geoff/ispell.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lasr.cs.ucla.edu/geoff/ispell.html</a></span></span></span>,
aspell<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><a href="http://aspell.net" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://aspell.net</a></span></span></span>, myspell and
hunspell<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><a href="http://hunspell.sf.net" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://hunspell.sf.net</a></span></span></span> and other *spell
derivatives. The hunspell dictionaries
provided with the OpenOffice.org suite cover 98 languages.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">The program-based spell-checking methods have their limitations
because they are based on specific program code that is extensible
only by coding new features into the system and getting all users to
upgrade. E.g. hunspell has limitations on what affix morphemes you can
attach to word roots with the consequence that not all languages with
rich inflectional morphologies can be conveniently implemented in
hunspell. This has already resulted in multiple new pieces of software
for a few languages with implementations to work around the
limitations, e.g. emberek (Turkish), hspell (Hebrew), uspell
(Yiddish) and voikko (Finnish). What we propose is to use a generic
framework of finite-state automata for these tasks. With finite-state
automata it is possible to implement the spell-checking functionality
as a one-tape weighted automaton containing the language model and a
two-tape weighted automaton containing the error model.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">We also extend the hunspell spell checking system by using simple corpus-based
unigram probability training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="Finite-state spell-checking with weighted language and error models" class="ltx_ref">8</a>]</cite>. With this probability
trained lexicon it is possible to fine-tune the spelling error suggestions</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">With this model, extensions to
context-based n-gram models for real-word spelling error problems
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="Real-word spelling correction with trigrams: a reconsideration of the mays, damerau, and mercer model" class="ltx_ref">9</a>]</cite> are also possible.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">We also provide a method for integrating the finite-state spell-checking
and hyphenation into applications using an open-source spell-checking
library voikko<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><a href="http://voikko.sf.net" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://voikko.sf.net</a></span></span></span>, which provides a
connection to typical open-source software, such as Mozilla Firefox,
OpenOffice.org and the Gnome desktop via enchant.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Definitions</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">In this article we use weighted two-tape finite-state automata—or
weighted finite-state transducers—for all processing. We use the
following symbol conventions to denote the parts of a weighted
finite-state automaton: a transducer <math id="S2.p1.m1" class="ltx_Math" alttext="T=(\Sigma,\Gamma,Q,q_{0},Q_{f},\delta,\rho)" display="inline"><mrow><mi>T</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">Σ</mi><mo>,</mo><mi mathvariant="normal">Γ</mi><mo>,</mo><mi>Q</mi><mo>,</mo><msub><mi>q</mi><mn>0</mn></msub><mo>,</mo><msub><mi>Q</mi><mi>f</mi></msub><mo>,</mo><mi>δ</mi><mo>,</mo><mi>ρ</mi><mo stretchy="false">)</mo></mrow></mrow></math> with a semi-ring <math id="S2.p1.m2" class="ltx_Math" alttext="(S,\oplus,\otimes,\overline{0},\overline{1})" display="inline"><mrow><mo stretchy="false">(</mo><mi>S</mi><mo>,</mo><mo>⊕</mo><mo>,</mo><mo>⊗</mo><mo>,</mo><mover accent="true"><mn>0</mn><mo>¯</mo></mover><mo>,</mo><mover accent="true"><mn>1</mn><mo>¯</mo></mover><mo stretchy="false">)</mo></mrow></math> for weights. Here <math id="S2.p1.m3" class="ltx_Math" alttext="\Sigma" display="inline"><mi mathvariant="normal">Σ</mi></math> is a set with
the input tape alphabet, <math id="S2.p1.m4" class="ltx_Math" alttext="\Gamma" display="inline"><mi mathvariant="normal">Γ</mi></math> is a set with the output tape
alphabet, <math id="S2.p1.m5" class="ltx_Math" alttext="Q" display="inline"><mi>Q</mi></math> a finite set of states in the transducer, <math id="S2.p1.m6" class="ltx_Math" alttext="q_{0}\in Q" display="inline"><mrow><msub><mi>q</mi><mn>0</mn></msub><mo>∈</mo><mi>Q</mi></mrow></math> is
an initial state of the transducer, <math id="S2.p1.m7" class="ltx_Math" alttext="Q_{f}\subset Q" display="inline"><mrow><msub><mi>Q</mi><mi>f</mi></msub><mo>⊂</mo><mi>Q</mi></mrow></math> is a set of finite
states, <math id="S2.p1.m8" class="ltx_Math" alttext="\delta:Q\times\Sigma\times\Gamma\times S\rightarrow Q" display="inline"><mrow><mi>δ</mi><mo>:</mo><mrow><mrow><mi>Q</mi><mo>×</mo><mi mathvariant="normal">Σ</mi><mo>×</mo><mi mathvariant="normal">Γ</mi><mo>×</mo><mi>S</mi></mrow><mo>→</mo><mi>Q</mi></mrow></mrow></math>
is a transition relation, <math id="S2.p1.m9" class="ltx_Math" alttext="\rho:Q_{f}\rightarrow S" display="inline"><mrow><mi>ρ</mi><mo>:</mo><mrow><msub><mi>Q</mi><mi>f</mi></msub><mo>→</mo><mi>S</mi></mrow></mrow></math> is a final weight
function. A successful path is a list of transitions from an initial
state to a final state with a weight different from <math id="S2.p1.m10" class="ltx_Math" alttext="\overline{0}" display="inline"><mover accent="true"><mn>0</mn><mo>¯</mo></mover></math>
collected from the transition function and the final state function in
the semi-ring <math id="S2.p1.m11" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> by the operation <math id="S2.p1.m12" class="ltx_Math" alttext="\otimes" display="inline"><mo>⊗</mo></math>. We typically denote a
successful path as a concatenation of input symbols, a colon and a
concatenation of output symbols. The weight of the successful path is
indicated as a subscript in angle brackets,
<math id="S2.p1.m13" class="ltx_Math" alttext="\textit{input:output}_{&lt;w&gt;}" display="inline"><msub><mtext mathvariant="italic">input:output</mtext><mrow><mo>&lt;</mo><mi>w</mi><mo>&gt;</mo></mrow></msub></math>. A path transducer is denoted by
subscripting a transducer with the path. If the input and output
symbols are the same, the colon and the output part can be omitted.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">The finite-state formulation we use in this article is based on Xerox
formalisms for finite-state methods in natural language processing
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="Finite state morphology" class="ltx_ref">1</a>]</cite>, in practice lexc is a formalism for writing right linear
grammars using morpheme sets called lexicons. Each morpheme in a lexc grammar
can define their right follower lexicon, creating a finite-state network called
a <em class="ltx_emph">lexical transducer</em>. In formulae, we denote a lexc style lexicon named <math id="S2.p2.m1" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> as
<math id="S2.p2.m2" class="ltx_Math" alttext="Lex_{X}" display="inline"><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mi>X</mi></msub></mrow></math> and use the shorthand notation <math id="S2.p2.m3" class="ltx_Math" alttext="Lex_{X}\cup\textit{input:output Y}" display="inline"><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mi>X</mi></msub></mrow><mo>∪</mo><mtext mathvariant="italic">input:output Y</mtext></mrow></math> to
denote the addition of a lexc string or morpheme, <span class="ltx_text ltx_font_typewriter">input:output Y ;</span> to
the <span class="ltx_text ltx_font_typewriter">LEXICON X</span>. In the same framework, the twolc formalism is used to
describe context restrictions for symbols and their realizations in the form of
parallel rules as defined in the appendix of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="Finite state morphology" class="ltx_ref">1</a>]</cite>. We use
<math id="S2.p2.m4" class="ltx_Math" alttext="Twol_{Z}" display="inline"><mrow><mi>T</mi><mo>⁢</mo><mi>w</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><msub><mi>l</mi><mi>Z</mi></msub></mrow></math> to denote the rule set <math id="S2.p2.m5" class="ltx_Math" alttext="Z" display="inline"><mi>Z</mi></math> and use the shorthand notation <math id="S2.p2.m6" class="ltx_Math" alttext="Twol_{Z}\cap\textit{a:b}\leftrightarrow\textit{l e f t}\_\textit{r i g h t}" display="inline"><mrow><mrow><mrow><mi>T</mi><mo>⁢</mo><mi>w</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><msub><mi>l</mi><mi>Z</mi></msub></mrow><mo>∩</mo><mtext mathvariant="italic">a:b</mtext></mrow><mo>↔</mo><mrow><mtext mathvariant="italic">l e f t</mtext><mo>⁢</mo><mi mathvariant="normal">_</mi><mo>⁢</mo><mtext mathvariant="italic">r i g h t</mtext></mrow></mrow></math> to denote
the addition of a rule string <span class="ltx_text ltx_font_typewriter">a:b &lt;=&gt; l e f t _ r i g h t ;</span> to the
rule set <math id="S2.p2.m7" class="ltx_Math" alttext="Z" display="inline"><mi>Z</mi></math>, effectively saying that <span class="ltx_text ltx_font_italic">a:b</span> only applies in
the specified context.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">A spell-checking dictionary is essentially a single-tape finite-state
automaton or a language model <math id="S2.p3.m1" class="ltx_Math" alttext="T_{L}" display="inline"><msub><mi>T</mi><mi>L</mi></msub></math>, where the alphabet <math id="S2.p3.m2" class="ltx_Math" alttext="\Sigma_{L}=\Gamma_{L}" display="inline"><mrow><msub><mi mathvariant="normal">Σ</mi><mi>L</mi></msub><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>L</mi></msub></mrow></math> are characters of a natural language. The successful paths
define the correctly spelled word-forms of the language
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="Finite-state spell-checking with weighted language and error models" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">For weighted spell-checking, we define the weights in lexicon as
as probability of the word in Wikipedia. For weight model of the automaton
we use the tropical semi-ring assigning each word-form the weight of
<math id="S2.p4.m1" class="ltx_Math" alttext="-\log\frac{f_{w}}{CS}" display="inline"><mrow><mo>-</mo><mrow><mi>log</mi><mo>⁡</mo><mfrac><msub><mi>f</mi><mi>w</mi></msub><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow></mfrac></mrow></mrow></math>, where <math id="S2.p4.m2" class="ltx_Math" alttext="f_{w}" display="inline"><msub><mi>f</mi><mi>w</mi></msub></math> is the frequency of the word and <math id="S2.p4.m3" class="ltx_Math" alttext="CS" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow></math>
the corpus size in number of word form tokens. For word-forms not appearing
in Wikipedia, we assign small probability by formula <math id="S2.p4.m4" class="ltx_Math" alttext="-\log\frac{1}{CS+1}" display="inline"><mrow><mo>-</mo><mrow><mi>log</mi><mo>⁡</mo><mfrac><mn>1</mn><mrow><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow><mo>+</mo><mn>1</mn></mrow></mfrac></mrow></mrow></math>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p class="ltx_p">A spelling correction model or an error model <math id="S2.p5.m1" class="ltx_Math" alttext="T_{E}" display="inline"><msub><mi>T</mi><mi>E</mi></msub></math> is a two-tape
automaton mapping the input text strings of the text to be
spell-checked into strings that may be in the language model. The
input alphabet <math id="S2.p5.m2" class="ltx_Math" alttext="\Sigma_{E}" display="inline"><msub><mi mathvariant="normal">Σ</mi><mi>E</mi></msub></math> is the alphabet of the text to be
spell-checked and the output alphabet is <math id="S2.p5.m3" class="ltx_Math" alttext="\Gamma_{E}=\Sigma_{L}" display="inline"><mrow><msub><mi mathvariant="normal">Γ</mi><mi>E</mi></msub><mo>=</mo><msub><mi mathvariant="normal">Σ</mi><mi>L</mi></msub></mrow></math>. For
practical applications, the input alphabet needs to be extended by a
special any symbol with the semantics of a character not belonging to
the alphabet of the language model in order to account for input text
containing typos outside the target natural language alphabet. The
error model can be composed with the language model, <math id="S2.p5.m4" class="ltx_Math" alttext="T_{L}\circ T_{E}" display="inline"><mrow><msub><mi>T</mi><mi>L</mi></msub><mo>∘</mo><msub><mi>T</mi><mi>E</mi></msub></mrow></math>,
to obtain an error model that only produces strings of the target
language. For space efficiency, the composition may be carried out
during run-time using the input string to limit the search space. The
weights of an error model may be used as an estimate for the likelihood of the
combination of errors. The error model is applied as a filter between
the path automaton <math id="S2.p5.m5" class="ltx_Math" alttext="T_{s}" display="inline"><msub><mi>T</mi><mi>s</mi></msub></math> compiled from the erroneous string, <math id="S2.p5.m6" class="ltx_Math" alttext="s\notin T_{L}" display="inline"><mrow><mi>s</mi><mo>∉</mo><msub><mi>T</mi><mi>L</mi></msub></mrow></math>, and the language model, <math id="S2.p5.m7" class="ltx_Math" alttext="T_{L}" display="inline"><msub><mi>T</mi><mi>L</mi></msub></math>, using two compositions, <math id="S2.p5.m8" class="ltx_Math" alttext="T_{s}\circ T_{E}\circ T_{L}" display="inline"><mrow><msub><mi>T</mi><mi>s</mi></msub><mo>∘</mo><msub><mi>T</mi><mi>E</mi></msub><mo>∘</mo><msub><mi>T</mi><mi>L</mi></msub></mrow></math>. The resulting transducer consists of a
potentially infinite set of paths relating an incorrect string with
correct strings from <math id="S2.p5.m9" class="ltx_Math" alttext="L" display="inline"><mi>L</mi></math>. The paths, <math id="S2.p5.m10" class="ltx_Math" alttext="s:s^{i}_{&lt;w_{i}&gt;}" display="inline"><mrow><mi>s</mi><mo>:</mo><msubsup><mi>s</mi><mrow><mo>&lt;</mo><msub><mi>w</mi><mi>i</mi></msub><mo>&gt;</mo></mrow><mi>i</mi></msubsup></mrow></math>, are weighted by
the error model and language model using the semi-ring multiplication
operation, <math id="S2.p5.m11" class="ltx_Math" alttext="\otimes" display="inline"><mo>⊗</mo></math>. If the error model and the language model
generate an infinite number of suggestions, the best suggestions may
be efficiently enumerated with some variant of the n-best-paths
algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="An efficient algorithm for the n-best-strings problem" class="ltx_ref">7</a>]</cite>. For automatic spelling corrections, the
best path may be used. If either the error model or the language model
is known to generate only a finite set of results, the suggestion
generation algorithm may be further optimized.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Material</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">In this article we present methods for converting the hunspell
dictionaries and rule sets for use with open-source finite-state
writer’s tools. As concrete dictionaries we use the repositories of
free implementations of these dictionaries and rule sets found on the
internet, e.g. for the hunspell dictionary files found on the
OpenOffice.org spell-checking
site<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><a href="http://wiki.services.openoffice.org/wiki/Dictionaries" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://wiki.services.openoffice.org/wiki/Dictionaries</a></span></span></span>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">In this section we describe the parts of the file formats we are
working with. All of the information of the hunspell format specifics
is derived from the
<span class="ltx_text ltx_font_typewriter">hunspell(4)<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><a href="http://manpages.ubuntu.com/manpages/dapper/man4/hunspell.4.html" title="" class="ltx_ref ltx_url">http://manpages.ubuntu.com/manpages/dapper/man4/hunspell.4.html</a></span></span></span></span>
man page, as that is the only normative documentation of hunspell we
have been able to locate.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">The corpora for spell-checking dictionaries’ unigram training used, are
wikipedia’s database backups<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><a href="http://download.wikimedia.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://download.wikimedia.org</a></span></span></span>. The
wikipedia is available in majority of languages, consisting large amount of
language that is typically well-suited for training a spell-checking dictionary.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Hunspell File Format</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">A hunspell spell-checking dictionary consists of two files: a
dictionary file and an affix file. The dictionary file contains only
root forms of words with information about morphological affix classes
to combine with the roots. The affix file contains lists of affixes
along with their context restrictions and effects, but the affix file
also serves as a settings file for the dictionary, containing all
meta-data and settings as well.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">The dictionary file starts with a number that is intended to be the
number of lines of root forms in the dictionary file, but in practice
many of the files have numbers different from the actual line count,
so it is safer to just treat it as a rough estimate. Following the
initial line is a list of strings containing the root forms of the
words in the morphology. Each word may be associated with an arbitrary
number of classes separated by a slash. The classes are encoded in one
of the three formats shown in the examples of
Figure <a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>: a list of binary octets
specifying classes from 1–255 (minus octets for CR, LF etc.), as in
the Swedish example on lines
<a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>–<a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, a list of
binary words, specifying classes from 1–65,535 (again ignoring octets
with CR and LF) or a comma separated list of numbers written in digits
specifying classes 1–65,535 as in the North SÃ¡mi examples on lines
<a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>–<a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We refer to
all of these as continuation classes encoded by their numeric decimal
values, e.g. ’abakus’ on line <a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> would have
continuation classes 72, 68 and 89 (the decimal values of the ASCII
code points for H, D and Y respectively). In the Hungarian example,
you can see the affix compression scheme, which refers to the line
numbers in the affix file containing the continuation class listings,
i.e. the part following the slash character in the previous two
examples. The lines of the Hungarian dictionary also contain some
extra numeric values separated by a tab which refer to the morphology
compression scheme that is also mentioned in the affix definition
file; this is used in the hunmorph morphological analyzer
functionality which is not implemented nor described in this paper.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_listing ltx_lst_numbers_left ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgICMgU3dlZGlzaAogICAgYWJha3VzL0hEWXwtXGxhYmVse3ZyYjpodW5zcGVsbGRpY3N2c3Rh%0AcnR9LXwKICAgIGFiYWxpZW5hdGlvbi9BSER2WQogICAgYWJhbGllbmVyYS9NWXwtXGxhYmVse3Zy%0AYjpodW5zcGVsbGRpY3N2ZW5kfS18CiAgICAjIE5vcnRoZXJuIFN8LVwne2F9LXxtaQogICAgb2t0%0AYS8xfC1cbGFiZWx7dnJiOmh1bnNwZWxsZGljc2VzdGFydH0tfAogICAgZ3Vva3RlLzEsMwogICAg%0AZ29sYm1hLzEsM3wtXGxhYmVse3ZyYjpodW5zcGVsbGRpY3NlZW5kfS18CiAgICAjIEh1bmdhcmlh%0AbgogICAgfC1cInt1fS18enwtXCd7ZX0tfHIvMSAgMXwtXGxhYmVse3ZyYjpodW5zcGVsbGRpY2h1%0Ac3RhcnR9LXwKICAgIHwtXCJ7dX0tfHpsZXR8LVwne2F9LXxnLzIgICAgICAgMgogICAgfC1cInt1%0AfS18emxldHZlemV0fC1cIntvfS18LzMgICAxCiAgICB8LVwie3V9LXx6bGV0c3plcnp8LVwie299%0ALXwvNCAgIDF8LVxsYWJlbHt2ZXJiOmh1bnNwZWxsZGljaHVlbmR9LXw=%0A">⬇</a></div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">1</span><span class="ltx_text ltx_lst_space">    </span>#<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Swedish</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">abakus</span>/<span class="ltx_text ltx_lst_identifier">HDY</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">3</span><span class="ltx_text ltx_lst_identifier">abalienation</span>/<span class="ltx_text ltx_lst_identifier">AHDvY</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">abalienera</span>/<span class="ltx_text ltx_lst_identifier">MY</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">5</span>#<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Northern</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">S</span>á<span class="ltx_text ltx_lst_identifier">mi</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">okta</span>/1
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">7</span><span class="ltx_text ltx_lst_identifier">guokte</span>/1,3
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">golbma</span>/1,3
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">9</span>#<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Hungarian</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ü<span class="ltx_text ltx_lst_identifier">z</span>é<span class="ltx_text ltx_lst_identifier">r</span>/1<span class="ltx_text ltx_lst_space">  </span>1
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">11</span>ü<span class="ltx_text ltx_lst_identifier">zlet</span>á<span class="ltx_text ltx_lst_identifier">g</span>/2<span class="ltx_text ltx_lst_space">       </span>2
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ü<span class="ltx_text ltx_lst_identifier">zletvezet</span>ö/3<span class="ltx_text ltx_lst_space">   </span>1
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">13</span>ü<span class="ltx_text ltx_lst_identifier">zletszerz</span>ö/4<span class="ltx_text ltx_lst_space">   </span>1
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Excerpts of Swedish, Northern S—-á-—mi and Hungarian dictionaries</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p">The second file in the hunspell dictionaries is the affix file,
containing all the settings for the dictionary, and all non-root
morphemes. The Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows parts of
the Hungarian affix file that we use for describing different setting
types. The settings are typically given on a single line composed of
the setting name in capitals, a space and the setting values, like the
NAME setting on line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The hunspell files
have some values encoded in UTF-8, some in the ISO 8859 encoding, and
some using both binary and ASCII data at the same time. Note that in the examples in this article, we have
transcribed everything into UTF-8 format or the nearest relevant encoded
character with a displayable code point.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p class="ltx_p">The settings we have used for building the spell-checking automata can
be roughly divided into the following four categories: meta-data, error
correction models, special continuation classes, and the actual
affixes. An excerpt of the parts that we use in the Hungarian affix file
is given in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p">The meta-data section contains, e.g., the name of the dictionary on
line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the character set encoding on
line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, and the type of parsing used for
continuation classes, which is omitted from the Hungarian lexicon
indicating 8-bit binary parsing.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p class="ltx_p">The error model settings each contain a small part of the actual error
model, such as the characters to be used for edit distance, their weights,
confusion sets and phonetic confusion sets. The list of word
characters in order of popularity, as seen on
line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> of
Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, is used for the edit distance
model. The keyboard layout, i.e. neighboring key sets, is specified
for the substitution error model on
line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Each set of the characters, separated by
vertical bars, is regarded as a possible slip-of-the-finger typing
error. The ordered confusion set of possible spelling error pairs is
given on
lines <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>–<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
where each line is a pair of a ‘mistyped’ and a ‘corrected’ word
separated by whitespace.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p class="ltx_p">The compounding model is defined by special continuation classes,
i.e. some of the continuation classes in the dictionary or affix file
may not lead to affixes, but are defined in the compounding section of
the settings in the affix file. In
Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the compounding rules are
specified on
lines <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>–<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The
flags in these settings are the same as in the affix definitions, so
the words in class 118 (corresponding to lower case v) would be
eligible as compound initial words, the words with class 120 (lower
case x) occur at the end of a compound, and words with 117 only occur
within a compound. Similarly, special flags are given to word forms
needing affixes that are used only for spell checking but not for the
suggestion mechanism, etc.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p class="ltx_p">The actual affixes are defined in three different parts of the file:
the compression scheme part on the
lines <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>–<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the
suffix definitions on the
lines <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>–<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, and
the prefix definitions on the
lines <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>–<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para">
<p class="ltx_p">The compression scheme is a grouping of frequently co-occurring
continuation classes. This is done by having the first AF line list a
set of continuation classes which are referred to as the continuation
class 1 in the dictionary, the second line is referred to the
continuation class 2, and so forth. This means that for example
continuation class 1 in the Hungarian dictionary refers to the classes
on line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> starting from 86 (V) and ending
with 108 (l).</p>
</div>
<div id="S3.SS1.p10" class="ltx_para">
<p class="ltx_p">The prefix and suffix definitions use the same structure. The prefixes
define the left-hand side context and deletions of a dictionary entry
whereas the suffixes deal with the right-hand side. The first line of
an affix set contains the class name, a boolean value defining whether
the affix participates in the prefix-suffix combinatorics and the
count of the number of morphemes in the continuation class, e.g. the
line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> defines the prefix continuation
class attaching to morphemes of class 114 (r) and it combines with
other affixes as defined by the Y instead of N in the third field. The
following lines describe the prefix morphemes as triplets of removal,
addition and context descriptions, e.g., the line
<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> defines removal of ’Ã¶’, addition of
’ős’ with continuation classes from AF line 1108, in case the
previous morpheme ends in ’Ã¶’. The context description may also
contain bracketed expressions for character classes or a fullstop
indicating any character (i.e. a wild-card) as in the POSIX regular
expressions, e.g. the context description on line
<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> matches any Hungarian vowel except a, e or
Ã¶, and the <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> matches any context. The
deletion and addition parts may also consist of a sole ‘0’ meaning a
zero-length string. As can be seen in the Hungarian example, the lines
may also contain an additional number at the end which is used for the
morphological analyzer functionalities.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_listing ltx_lst_numbers_left ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgIEFGIDEyNjMgfC1cbGFiZWx7dnJiOmh1bnNwZWxsYWZmYWZzdGFydH0tfAogICAgQUYgVnwt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%0AfAogICAgIyAxOTMgbW9yZSBQRlggciBsaW5lcw==%0A">⬇</a></div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">1</span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">AF</span><span class="ltx_text ltx_lst_space"> </span>1263<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">AF</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">V</span>Ë-j<span class="ltx_text ltx_lst_identifier">xLn</span>Óéè3Ää<span class="ltx_text ltx_lst_identifier">TtYc</span>,4<span class="ltx_text ltx_lst_identifier">l</span><span class="ltx_text ltx_lst_space"> </span>#<span class="ltx_text ltx_lst_space"> </span>1<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">3</span><span class="ltx_text ltx_lst_identifier">AF</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Um</span>Ö<span class="ltx_text ltx_lst_identifier">yiYc</span>Ç<span class="ltx_text ltx_lst_space"> </span>#<span class="ltx_text ltx_lst_space"> </span>2
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">AF</span><span class="ltx_text ltx_lst_space"> </span>Ö<span class="ltx_text ltx_lst_identifier">CWR</span>Í-jÃ°Óí<span class="ltx_text ltx_lst_identifier">y</span>ÉÁÿ<span class="ltx_text ltx_lst_identifier">Yc2</span><span class="ltx_text ltx_lst_space"> </span>#<span class="ltx_text ltx_lst_space"> </span>3<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">5</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">NAME</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Magyar</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Ispell</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">helyes</span>í<span class="ltx_text ltx_lst_identifier">r</span>á<span class="ltx_text ltx_lst_identifier">si</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">sz</span>ó<span class="ltx_text ltx_lst_identifier">t</span>á<span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space">     </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">7</span><span class="ltx_text ltx_lst_identifier">LANG</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">hu_HU</span><span class="ltx_text ltx_lst_space">     </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">SET</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">UTF</span>-8<span class="ltx_text ltx_lst_space">     </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">9</span><span class="ltx_text ltx_lst_identifier">KEY</span><span class="ltx_text ltx_lst_space"> </span>öüó|<span class="ltx_text ltx_lst_identifier">qwertzuiop</span>őú|<span class="ltx_text ltx_lst_space"> </span>#<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">wrap</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">asdfgh</span>j<span class="ltx_text ltx_lst_identifier">kl</span>éáűí<span class="ltx_text ltx_lst_identifier">yxcvbnm</span><span class="ltx_text ltx_lst_space">        </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">11</span><span class="ltx_text ltx_lst_identifier">TRY</span><span class="ltx_text ltx_lst_space"> </span>íóú<span class="ltx_text ltx_lst_identifier">taeslz</span>á<span class="ltx_text ltx_lst_identifier">norhgki</span>é<span class="ltx_text ltx_lst_space"> </span>#<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">wrap</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">dmy</span>ő<span class="ltx_text ltx_lst_identifier">pv</span>ö<span class="ltx_text ltx_lst_identifier">bucf</span>jü<span class="ltx_text ltx_lst_identifier">yxwq</span>-.á<span class="ltx_text ltx_lst_space">      </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">13</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">COMPOUNDBEGIN</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">v</span><span class="ltx_text ltx_lst_space">     </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">15</span><span class="ltx_text ltx_lst_identifier">COMPOUNDEND</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">ONLYINCOMPOUND</span><span class="ltx_text ltx_lst_space"> </span>|<span class="ltx_text ltx_lst_space">     </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">17</span><span class="ltx_text ltx_lst_identifier">NEEDAFFIX</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">u</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">19</span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span>125<span class="ltx_text ltx_lst_space">        </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span>í<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">i</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">21</span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span>í
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span>ó<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">o</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">23</span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">oliere</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">oli</span>é<span class="ltx_text ltx_lst_identifier">re</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">cc</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">gysz</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">25</span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">cs</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ts</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">cs</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ds</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">27</span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ccs</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ts</span><span class="ltx_text ltx_lst_space">       </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>#<span class="ltx_text ltx_lst_space"> </span>116<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">more</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">lines</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">29</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">SFX</span><span class="ltx_text ltx_lst_space"> </span>?<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Y</span><span class="ltx_text ltx_lst_space"> </span>3<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">31</span><span class="ltx_text ltx_lst_identifier">SFX</span><span class="ltx_text ltx_lst_space"> </span>?<span class="ltx_text ltx_lst_space"> </span>ö<span class="ltx_text ltx_lst_space"> </span>ő<span class="ltx_text ltx_lst_identifier">s</span>/1108<span class="ltx_text ltx_lst_space"> </span>ö<span class="ltx_text ltx_lst_space"> </span>20973<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">SFX</span><span class="ltx_text ltx_lst_space"> </span>?<span class="ltx_text ltx_lst_space"> </span>0<span class="ltx_text ltx_lst_space"> </span>ö<span class="ltx_text ltx_lst_identifier">s</span>/1108<span class="ltx_text ltx_lst_space"> </span>[^<span class="ltx_text ltx_lst_identifier">a</span>á<span class="ltx_text ltx_lst_identifier">e</span>é<span class="ltx_text ltx_lst_identifier">i</span>í<span class="ltx_text ltx_lst_identifier">o</span>óöő<span class="ltx_text ltx_lst_identifier">u</span>üű]<span class="ltx_text ltx_lst_space"> </span>20973
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">33</span><span class="ltx_text ltx_lst_identifier">SFX</span><span class="ltx_text ltx_lst_space"> </span>?<span class="ltx_text ltx_lst_space"> </span>0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">s</span>/1108<span class="ltx_text ltx_lst_space"> </span>[áé<span class="ltx_text ltx_lst_identifier">i</span>í<span class="ltx_text ltx_lst_identifier">o</span>óúő<span class="ltx_text ltx_lst_identifier">u</span>úüű-]<span class="ltx_text ltx_lst_space"> </span>20973<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">35</span><span class="ltx_text ltx_lst_identifier">PFX</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Y</span><span class="ltx_text ltx_lst_space"> </span>195<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">PFX</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span>0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">leg</span>új<span class="ltx_text ltx_lst_identifier">ra</span>/1262<span class="ltx_text ltx_lst_space"> </span>.<span class="ltx_text ltx_lst_space"> </span>22551
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">37</span><span class="ltx_text ltx_lst_identifier">PFX</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span>0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">leg</span>újjá/1262<span class="ltx_text ltx_lst_space"> </span>.<span class="ltx_text ltx_lst_space"> </span>22552<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>#<span class="ltx_text ltx_lst_space"> </span>193<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">more</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">PFX</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">lines</span>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Excerpts from Hungarian affix file</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methods</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">This article presents methods for converting the existing spell-checking
dictionaries with error models, as well as hyphenators to finite-state
automata. As our toolkit we use the free open-source HFST
toolkit<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><a href="http://HFST.sf.net" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://HFST.sf.net</a></span></span></span>, which is a general purpose API for
finite-state automata, and a set of tools for using legacy data, such as Xerox
finite-state morphologies. For this reason this paper presents the algorithms
as formulae such that they can be readily implemented using finite-state
algebra and the basic HFST tools.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">The lexc lexicon model is used by the tools for describing parts of the
morphotactics. It is a simple right-linear grammar for specifying finite-state
automata described in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">beesley2003finitestate</span>, <a href="#bib.bib70" title="HFST tools for morphology—an efficient open-source package for construction of morphological analyzers" class="ltx_ref">5</a>]</cite>. The twolc rule
formalism is used for defining context-based rules with two-level automata and
they are described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="Two-level morphology: a general computational model for word-form recognition and production" class="ltx_ref">4</a>, <a href="#bib.bib70" title="HFST tools for morphology—an efficient open-source package for construction of morphological analyzers" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">This section presents both a pseudo-code presentation for the conversion
algorithms, as well as excerpts of the final converted files from the material
given in Figures <a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:tex-hyph-example</span> of
Section <a href="#S3" title="3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The converter code is available in the HFST SVN
repository<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><a href="http://hfst.svn.sourceforge.net/viewvc/hfst/trunk/conversion-scripts/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://hfst.svn.sourceforge.net/viewvc/hfst/trunk/conversion-scripts/</a></span></span></span>
, for those who wish to see the specifics of the implementation in
lex, yacc, c and python.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Hunspell dictionary conversion</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">The hunspell dictionaries are transformed into a finite-state transducer
language model by a finite-state formulation consisting of two parts: a lexicon
and one or more rule sets. The root and affix dictionaries are turned into
finite-state lexicons in the lexc formalism. The Lexc formalism models the part
of the morphotax concerning the root dictionary and the adjacent suffixes. The
rest is encoded by injecting special symbols, called flag diacritics, into the
morphemes restricting the morpheme co-occurrences by implicit rules that have
been outlined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="Constraining separated morphotactic dependencies in finite-state grammars" class="ltx_ref">2</a>]</cite>; the flag diacritics are denoted in lexc
by at-sign delimited substrings. The affix definitions in hunspell also define
deletions and context restrictions which are turned into explicit two-level
rules.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p">The pseudo-code for the conversion of hunspell files is provided in
Algorithm <a href="#alg1" title="Algorithm 1 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and excerpts from the conversion of the examples
in Figures <a href="#S3.F1" title="Figure 1 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>
can be found in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The dictionary file of
hunspell is almost identical to the lexc root lexicon, and the conversion is
straightforward. This is expressed on lines <a href="#alg1.l4" title="4 ‣ Algorithm 1 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>–<a href="#alg1.l9" title="9 ‣ Algorithm 1 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> as simply going
through all entries and adding them to the root lexicon, as in
lines <a href="#S4.F3" title="Figure 3 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>—<a href="#S4.F3" title="Figure 3 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> of the example result. The handling of
affixes is similar, with the exception of adding flag diacritics for
co-occurrence restrictions along with the morphemes. This is shown on
lines <a href="#alg1.l10" title="10 ‣ Algorithm 1 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>—<a href="#alg1.l28" title="28 ‣ Algorithm 1 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">28</span></a> of the pseudo-code, and applying it will create the
lines <a href="#S4.F3" title="Figure 3 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>—<a href="#S4.F3" title="Figure 3 ‣ 4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> of the Swedish example, which does not contain further
restrictions on suffixes.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p">To finalize the morpheme and compounding restrictions, the final lexicon in the
lexc description must be a lexicon checking that all prefixes with forward requirements
have their requiring flags turned off.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Algorithm 1 </span>Extracting morphemes from hunspell dictionaries</figcaption>
<div class="ltx_listing ltx_framed_topbottom ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <math id="alg1.l1.m1" class="ltx_Math" alttext="finalflags\leftarrow\epsilon" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mi>ϵ</mi></mrow></math>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">2:</span></span>  <span class="ltx_text ltx_font_bold">for all</span> lines <math id="alg1.l2.m1" class="ltx_Math" alttext="morpheme/Conts" display="inline"><mrow><mrow><mrow><mi>m</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>p</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>m</mi><mo>⁢</mo><mi>e</mi></mrow><mo>/</mo><mi>C</mi></mrow><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></math> in dic <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg1.l3.m1" class="ltx_Math" alttext="flags\leftarrow\epsilon" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mi>ϵ</mi></mrow></math>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">4:</span></span>     <span class="ltx_text ltx_font_bold">for all</span> <math id="alg1.l4.m1" class="ltx_Math" alttext="cont" display="inline"><mrow><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi></mrow></math> in <math id="alg1.l4.m2" class="ltx_Math" alttext="Conts" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></math>  <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>        <math id="alg1.l5.m1" class="ltx_Math" alttext="flags\leftarrow flags+\textit{@C.cont@}" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>+</mo><mtext mathvariant="italic">@C.cont@</mtext></mrow></mrow></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">6:</span></span>        <math id="alg1.l6.m1" class="ltx_Math" alttext="Lex_{Conts}\leftarrow Lex_{Conts}\cup\textit{0:[&lt;cont] cont}" display="inline"><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>C</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>C</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></msub></mrow><mo>∪</mo><mtext mathvariant="italic">0:[¡cont] cont</mtext></mrow></mrow></math>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">8:</span></span>     <math id="alg1.l8.m1" class="ltx_Math" alttext="Lex_{Root}\leftarrow Lex_{Root}\cup\textit{flags + morpheme Conts}" display="inline"><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>R</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>t</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>R</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>t</mi></mrow></msub></mrow><mo>∪</mo><mtext mathvariant="italic">flags + morpheme Conts</mtext></mrow></mrow></math>

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">10:</span></span>  <span class="ltx_text ltx_font_bold">for all</span> suffixes <math id="alg1.l10.m1" class="ltx_Math" alttext="lex,deletions,morpheme/Conts,context" display="inline"><mrow><mrow><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi></mrow><mo>,</mo><mrow><mi>d</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow><mo>,</mo><mrow><mrow><mrow><mi>m</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>p</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>m</mi><mo>⁢</mo><mi>e</mi></mrow><mo>/</mo><mi>C</mi></mrow><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow><mo>,</mo><mrow><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi><mo>⁢</mo><mi>t</mi></mrow></mrow></math> in aff  <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg1.l11.m1" class="ltx_Math" alttext="flags\leftarrow\epsilon" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mi>ϵ</mi></mrow></math>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">12:</span></span>     <span class="ltx_text ltx_font_bold">for all</span> <math id="alg1.l12.m1" class="ltx_Math" alttext="cont" display="inline"><mrow><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi></mrow></math> in <math id="alg1.l12.m2" class="ltx_Math" alttext="Conts" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></math> <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>        <math id="alg1.l13.m1" class="ltx_Math" alttext="flags\leftarrow flags+\textit{@C.cont@}" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>+</mo><mtext mathvariant="italic">@C.cont@</mtext></mrow></mrow></math>

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">14:</span></span>        <math id="alg1.l14.m1" class="ltx_Math" alttext="Lex_{Conts}\leftarrow Lex_{Conts}\cup\textit{0 cont}" display="inline"><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>C</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>C</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow></msub></mrow><mo>∪</mo><mtext mathvariant="italic">0 cont</mtext></mrow></mrow></math>

</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">16:</span></span>     <math id="alg1.l16.m1" class="ltx_Math" alttext="Lex_{lex}\leftarrow Lex_{lex}\cup\textit{flags}+[&lt;lex]+\textit{morpheme Conts}" display="inline"><mrow><mi>L</mi><mi>e</mi><msub><mi>x</mi><mrow><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi></mrow></msub><mo>←</mo><mi>L</mi><mi>e</mi><msub><mi>x</mi><mrow><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi></mrow></msub><mo>∪</mo><mtext>𝑓𝑙𝑎𝑔𝑠</mtext><mo>+</mo><mrow><mo stretchy="false">[</mo><mo>&lt;</mo><mi>l</mi><mi>e</mi><mi>x</mi><mo stretchy="false">]</mo></mrow><mo>+</mo><mtext mathvariant="italic">morpheme Conts</mtext></mrow></math>

</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <span class="ltx_text ltx_font_bold">for all</span> <math id="alg1.l17.m1" class="ltx_Math" alttext="del" display="inline"><mrow><mi>d</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>l</mi></mrow></math> in <math id="alg1.l17.m2" class="ltx_Math" alttext="deletions" display="inline"><mrow><mi>d</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow></math> <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">18:</span></span>        <math id="alg1.l18.m1" class="ltx_Math" alttext="lc\leftarrow context+deletions\textrm{ before del}" display="inline"><mrow><mrow><mi>l</mi><mo>⁢</mo><mi>c</mi></mrow><mo>←</mo><mrow><mrow><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi><mo>⁢</mo><mi>t</mi></mrow><mo>+</mo><mrow><mi>d</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mtext> before del</mtext></mrow></mrow></mrow></math>

</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>        <math id="alg1.l19.m1" class="ltx_Math" alttext="rc\leftarrow deletions\textrm{ after del}+[&lt;lex]+morpheme" display="inline"><mrow><mi>r</mi><mi>c</mi><mo>←</mo><mi>d</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mtext> after del</mtext><mo>+</mo><mrow><mo stretchy="false">[</mo><mo>&lt;</mo><mi>l</mi><mi>e</mi><mi>x</mi><mo stretchy="false">]</mo></mrow><mo>+</mo><mi>m</mi><mi>o</mi><mi>r</mi><mi>p</mi><mi>h</mi><mi>e</mi><mi>m</mi><mi>e</mi></mrow></math>

</div>
<div id="alg1.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">20:</span></span>        <math id="alg1.l20.m1" class="ltx_Math" alttext="Twol_{d}\leftarrow Twol_{d}\cap\textit{del:0}\Leftrightarrow\textit{lc \_ rc}" display="inline"><mrow><mrow><mrow><mi>T</mi><mo>⁢</mo><mi>w</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><msub><mi>l</mi><mi>d</mi></msub></mrow><mo>←</mo><mrow><mrow><mi>T</mi><mo>⁢</mo><mi>w</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><msub><mi>l</mi><mi>d</mi></msub></mrow><mo>∩</mo><mtext mathvariant="italic">del:0</mtext></mrow></mrow><mo>⇔</mo><mtext mathvariant="italic">lc _ rc</mtext></mrow></math>

</div>
<div id="alg1.l21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">22:</span></span>     <math id="alg1.l22.m1" class="ltx_Math" alttext="Twol_{m}\leftarrow Twol_{m}\cap[&lt;lex]:0\Leftrightarrow\textit{context \_ morpheme}" display="inline"><mrow><mrow><mrow><mi>T</mi><mo>⁢</mo><mi>w</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><msub><mi>l</mi><mi>m</mi></msub></mrow><mo>←</mo><mrow><mrow><mrow><mi>T</mi><mo>⁢</mo><mi>w</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><msub><mi>l</mi><mi>m</mi></msub></mrow><mo>∩</mo></mrow><mspace width="veryverythickmathspace"></mspace><mrow><mo stretchy="false">[</mo><mrow><mi></mi><mo>&lt;</mo><mrow><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi></mrow></mrow><mo stretchy="false">]</mo></mrow></mrow></mrow><mo>:</mo><mn>0</mn><mo>⇔</mo><mtext mathvariant="italic">context _ morpheme</mtext></mrow></math>

</div>
<div id="alg1.l23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">24:</span></span>  <span class="ltx_text ltx_font_bold">for all</span> prefixes <math id="alg1.l24.m1" class="ltx_Math" alttext="lex,deletions,morpheme/conts,context" display="inline"><mrow><mrow><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi></mrow><mo>,</mo><mrow><mi>d</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow><mo>,</mo><mrow><mrow><mrow><mi>m</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>p</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>m</mi><mo>⁢</mo><mi>e</mi></mrow><mo>/</mo><mi>c</mi></mrow><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>s</mi></mrow><mo>,</mo><mrow><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi><mo>⁢</mo><mi>t</mi></mrow></mrow></math> in aff <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg1.l25.m1" class="ltx_Math" alttext="flags\leftarrow\textit{@P.lex@}" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mtext mathvariant="italic">@P.lex@</mtext></mrow></math>

</div>
<div id="alg1.l26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">26:</span></span>     <math id="alg1.l26.m1" class="ltx_Math" alttext="finalflags\leftarrow finalflags+\textit{@D.lex@}" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>←</mo><mrow><mrow><mi>f</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>s</mi></mrow><mo>+</mo><mtext mathvariant="italic">@D.lex@</mtext></mrow></mrow></math>

</div>
<div id="alg1.l27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg1.l27.m1" class="ltx_Math" alttext="lex\rightarrow prefixes" display="inline"><mrow><mrow><mi>l</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>x</mi></mrow><mo>→</mo><mrow><mi>p</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>x</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>s</mi></mrow></mrow></math>
{othewise as with suffixes, swapping left and right}

</div>
<div id="alg1.l28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">28:</span></span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>

</div>
<div id="alg1.l29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <math id="alg1.l29.m1" class="ltx_Math" alttext="Lex_{end}\leftarrow Lex_{end}\cup\textit{finalflags \#}" display="inline"><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>e</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>d</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>e</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>d</mi></mrow></msub></mrow><mo>∪</mo><mtext mathvariant="italic">finalflags #</mtext></mrow></mrow></math>

</div>
</div>
</figure>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_listing ltx_lst_numbers_left ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgIExFWElDT04gUm9vdAogICAgICAgIEhVTlNQRUxMX3BmeCA7CiAgICAgICAgSFVOUEVMTF9k%0AaWMgOwoKICAgICEgc3dlZGlzaCBsZXhjCiAgICBMRVhJQ09OIEhVTlNQRUxMX2RpYyB8LVxsYWJl%0AbHtjfS18CiAgICBAQy5IQEBDLkRAQEMuWUBhYmFrdXMgSERZIDsKICAgIEBDLkFAQEMuSEBAQy5E%0AQEBDLnZAQEMuWUBhYmFsaWVuYXRpb24KICAgICAgICBIVU5TUEVMTF9BSER2WSA7CiAgICBAQy5N%0AQEBDLllAYWJhbGllbmVyYSBNWSA7IHwtXGxhYmVse2R9LXwKCiAgICBMRVhJQ09OIEhEWQogICAg%0AMDpbPEhdICAgIEggOwogICAgMDpbPERdICAgIEQgOwogICAgMDpbPFldICAgIFkgOwoKICAgIExF%0AWElDT04gSCB8LVxsYWJlbHtlfS18CiAgICBlciAgSFVOU1BFTExfZW5kIDsKICAgIGVycyAgSFVO%0AU1BFTExfZW5kIDsKICAgIGVyICBIVU5TUEVMTF9lbmQgOwogICAgZXJzICBIVU5TUEVMTF9lbmQg%0AOyB8LVxsYWJlbHtmfS18CgogICAgTEVYSUNPTiBIVU5TUEVMTF9lbmQKICAgIEBELkhAQEQuREBA%0ARC5ZQEBELkFAQEQudkBARC5tQCAjIDsKCiAgICAhIHN3ZWRpc2ggdHdvbGMgZmlsZQogICAgUnVs%0AZXMKICAgICJTdWZmaXggSCBhbGxvd2VkIGNvbnRleHRzIgogICAgJVslPEglXTogMCA8PT4gXCBh%0AIF8gZSByIDsKICAgICAgICBcIGEgXyBlIHIgcyA7CiAgICAgICAgYTowIF8gZSByIDsKICAgICAg%0AICBhOjAgXyBlIHIgcyA7CgogICAgImEgZGVsZXRpb24gY29udGV4dHMiCiAgICBhOjAgPD0+IF8g%0AJVslPEglXTowIGUgciA7CiAgICAgICAgXyAlWyU8SCVdOiBlIHIgcyA7%0A">⬇</a></div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">1</span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Root</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_pfx</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">3</span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">HUNPELL_dic</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">5</span>!<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">swedish</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">lexc</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_dic</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">7</span><span class="ltx_text ltx_lst_identifier">@C</span>.<span class="ltx_text ltx_lst_identifier">H@@C</span>.<span class="ltx_text ltx_lst_identifier">D@@C</span>.<span class="ltx_text ltx_lst_identifier">Y@abakus</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HDY</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">@C</span>.<span class="ltx_text ltx_lst_identifier">A@@C</span>.<span class="ltx_text ltx_lst_identifier">H@@C</span>.<span class="ltx_text ltx_lst_identifier">D@@C</span>.<span class="ltx_text ltx_lst_identifier">v@@C</span>.<span class="ltx_text ltx_lst_identifier">Y@abalienation</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">9</span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_AHDvY</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">@C</span>.<span class="ltx_text ltx_lst_identifier">M@@C</span>.<span class="ltx_text ltx_lst_identifier">Y@abalienera</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">MY</span><span class="ltx_text ltx_lst_space"> </span>;<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">11</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HDY</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">13</span>0:[&lt;<span class="ltx_text ltx_lst_identifier">H</span>]<span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">H</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>0:[&lt;<span class="ltx_text ltx_lst_identifier">D</span>]<span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">D</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">15</span>0:[&lt;<span class="ltx_text ltx_lst_identifier">Y</span>]<span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">Y</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">17</span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">H</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">er</span><span class="ltx_text ltx_lst_space">  </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_end</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">19</span><span class="ltx_text ltx_lst_identifier">ers</span><span class="ltx_text ltx_lst_space">  </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_end</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">er</span><span class="ltx_text ltx_lst_space">  </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_end</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">21</span><span class="ltx_text ltx_lst_identifier">ers</span><span class="ltx_text ltx_lst_space">  </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_end</span><span class="ltx_text ltx_lst_space"> </span>;<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">23</span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_end</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">@D</span>.<span class="ltx_text ltx_lst_identifier">H@@D</span>.<span class="ltx_text ltx_lst_identifier">D@@D</span>.<span class="ltx_text ltx_lst_identifier">Y@@D</span>.<span class="ltx_text ltx_lst_identifier">A@@D</span>.<span class="ltx_text ltx_lst_identifier">v@@D</span>.<span class="ltx_text ltx_lst_identifier">m@</span><span class="ltx_text ltx_lst_space"> </span>#<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">25</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>!<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">swedish</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">twolc</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">file</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">27</span><span class="ltx_text ltx_lst_identifier">Rules</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>”<span class="ltx_text ltx_lst_identifier">Suffix</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">H</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">allowed</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">contexts</span>”
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">29</span>%[%&lt;<span class="ltx_text ltx_lst_identifier">H</span>%]:<span class="ltx_text ltx_lst_space"> </span>0<span class="ltx_text ltx_lst_space"> </span>&lt;=&gt;<span class="ltx_text ltx_lst_space"> </span>\<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">a</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">e</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_space">    </span>\<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">a</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">e</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">s</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">31</span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">a</span>:0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">e</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">a</span>:0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">e</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">s</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">33</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>”<span class="ltx_text ltx_lst_identifier">a</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deletion</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">contexts</span>”
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">35</span><span class="ltx_text ltx_lst_identifier">a</span>:0<span class="ltx_text ltx_lst_space"> </span>&lt;=&gt;<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span><span class="ltx_text ltx_lst_space"> </span>%[%&lt;<span class="ltx_text ltx_lst_identifier">H</span>%]:0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">e</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">_</span><span class="ltx_text ltx_lst_space"> </span>%[%&lt;<span class="ltx_text ltx_lst_identifier">H</span>%]:<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">e</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">r</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">s</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Converted dic and aff lexicons and rules governing the deletions</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Hunspell Error Models</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p">The hunspell dictionary configuration file, i.e. the affix file, contains
several parts that need to be combined to achieve a similar error correction
model as in the hunspell lexicon.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p">The error model part defined in the KEY section allows for one slip of
the finger in any of the keyboard neighboring classes. This is implemented by
creating a simple homogeneously weighted crossproduct of each class, as given
on lines <a href="#alg2.l1" title="1 ‣ Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>–<a href="#alg2.l7" title="7 ‣ Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> of
Algorithm <a href="#alg2" title="Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. For the first part of the example on
line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> of Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, this
results in the lexc lexicon on
lines <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>–<a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> in
Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p">The error model part defined in the REP section is an arbitrarily long ordered
confusion set. This is implemented by simply encoding them as increasingly
weighted paths, as shown in lines
<a href="#alg2.l9" title="9 ‣ Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>–<a href="#alg2.l12" title="12 ‣ Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> of the pseudo-code in
Algorithm <a href="#alg2" title="Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p class="ltx_p">The TRY section such as the one on line <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> of
Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Hunspell File Format ‣ 3 Material ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, defines characters to be tried as the
edit distance grows in descending order. For a more detailed formulation of a
weighted edit distance transducer, see e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="Finite-state spell-checking with weighted language and error models" class="ltx_ref">8</a>]</cite>). We
created an edit distance model with the sum of the positions of the characters
in the TRY string as the weight, which is defined on
lines <a href="#alg2.l14" title="14 ‣ Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>–<a href="#alg2.l21" title="21 ‣ Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">21</span></a> of the pseudo-code in
Algorithm <a href="#alg2" title="Algorithm 2 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The initial part of the converted example
is displayed on lines <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>–<a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> of
Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p class="ltx_p">Finally to attribute different likelihood to different parts of the error
models we use different weight magnitudes on different types of errors, and
to allow only correctly written substrings, we restrict the result by the
root lexicon and morfotax lexicon, as given on
lines <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>–<a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> of
Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. With the weights on
lines <a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>–<a href="#S4.F4" title="Figure 4 ‣ 4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we ensure that KEY
errors are always suggested before REP errors and REP errors before TRY errors.
Even though the error model allows only one error of any type, simulating the
original hunspell, the resulting transducer can be transformed into an error
model accepting multiple errors by a simple FST algebraic concatenative
n-closure, i.e. repetition.</p>
</div>
<figure id="alg2" class="ltx_float ltx_float_algorithm ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Algorithm 2 </span>Extracting patterns for hunspell error models</figcaption>
<div class="ltx_listing ltx_framed_topbottom ltx_listing">
<div id="alg2.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <span class="ltx_text ltx_font_bold">for all</span> neighborsets <math id="alg2.l1.m1" class="ltx_Math" alttext="ns" display="inline"><mrow><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow></math> in KEY  <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg2.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">2:</span></span>     <span class="ltx_text ltx_font_bold">for all</span> character <math id="alg2.l2.m1" class="ltx_Math" alttext="c" display="inline"><mi>c</mi></math> in <math id="alg2.l2.m2" class="ltx_Math" alttext="ns" display="inline"><mrow><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow></math> <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg2.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>        <span class="ltx_text ltx_font_bold">for all</span> character <math id="alg2.l3.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> in <math id="alg2.l3.m2" class="ltx_Math" alttext="ns" display="inline"><mrow><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow></math> such that <math id="alg2.l3.m3" class="ltx_Math" alttext="c!=d" display="inline"><mrow><mrow><mi>c</mi><mo lspace="0pt" rspace="3.5pt">!</mo></mrow><mo>=</mo><mi>d</mi></mrow></math> <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg2.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">4:</span></span>           <math id="alg2.l4.m1" class="ltx_Math" alttext="Lex_{KEY}\leftarrow Lex_{KEY}\cup c:d_{&lt;0&gt;}\#" display="inline"><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>K</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>K</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>∪</mo><mi>c</mi></mrow></mrow><mo>:</mo><mrow><msub><mi>d</mi><mrow><mo>&lt;</mo><mn>0</mn><mo>&gt;</mo></mrow></msub><mo>⁢</mo><mi mathvariant="normal">#</mi></mrow></mrow></math>

</div>
<div id="alg2.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>        <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg2.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">6:</span></span>     <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg2.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>

</div>
<div id="alg2.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">8:</span></span>  <math id="alg2.l8.m1" class="ltx_Math" alttext="w\leftarrow 0" display="inline"><mrow><mi>w</mi><mo>←</mo><mn>0</mn></mrow></math>

</div>
<div id="alg2.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <span class="ltx_text ltx_font_bold">for all</span> pairs <math id="alg2.l9.m1" class="ltx_Math" alttext="wrong,right" display="inline"><mrow><mrow><mi>w</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>g</mi></mrow><mo>,</mo><mrow><mi>r</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><mi>t</mi></mrow></mrow></math> in REP  <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg2.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">10:</span></span>     <math id="alg2.l10.m1" class="ltx_Math" alttext="w\leftarrow w+1" display="inline"><mrow><mi>w</mi><mo>←</mo><mrow><mi>w</mi><mo>+</mo><mn>1</mn></mrow></mrow></math>

</div>
<div id="alg2.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg2.l11.m1" class="ltx_Math" alttext="LEX_{REP}\leftarrow LEX_{REP}\cup wrong:right_{&lt;w&gt;}\#" display="inline"><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><msub><mi>X</mi><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mi>P</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><msub><mi>X</mi><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mi>P</mi></mrow></msub></mrow><mo>∪</mo><mrow><mi>w</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>g</mi></mrow></mrow></mrow><mo>:</mo><mrow><mi>r</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><msub><mi>t</mi><mrow><mo>&lt;</mo><mi>w</mi><mo>&gt;</mo></mrow></msub><mo>⁢</mo><mi mathvariant="normal">#</mi></mrow></mrow></math>

</div>
<div id="alg2.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">12:</span></span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>

</div>
<div id="alg2.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <math id="alg2.l13.m1" class="ltx_Math" alttext="w\leftarrow 0" display="inline"><mrow><mi>w</mi><mo>←</mo><mn>0</mn></mrow></math>

</div>
<div id="alg2.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">14:</span></span>  <span class="ltx_text ltx_font_bold">for all</span> character <math id="alg2.l14.m1" class="ltx_Math" alttext="c" display="inline"><mi>c</mi></math> in TRY  <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg2.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg2.l15.m1" class="ltx_Math" alttext="w\leftarrow w+1" display="inline"><mrow><mi>w</mi><mo>←</mo><mrow><mi>w</mi><mo>+</mo><mn>1</mn></mrow></mrow></math>

</div>
<div id="alg2.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">16:</span></span>     <math id="alg2.l16.m1" class="ltx_Math" alttext="Lex_{TRY}\leftarrow Lex_{TRY}\cup c:0_{&lt;w&gt;}\#" display="inline"><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>T</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>T</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>∪</mo><mi>c</mi></mrow></mrow><mo>:</mo><mrow><msub><mn>0</mn><mrow><mo>&lt;</mo><mi>w</mi><mo>&gt;</mo></mrow></msub><mo>⁢</mo><mi mathvariant="normal">#</mi></mrow></mrow></math>

</div>
<div id="alg2.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>     <math id="alg2.l17.m1" class="ltx_Math" alttext="Lex_{TRY}\leftarrow Lex_{TRY}\cup 0:c_{&lt;w&gt;}\#" display="inline"><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>T</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>T</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>∪</mo><mn>0</mn></mrow></mrow><mo>:</mo><mrow><msub><mi>c</mi><mrow><mo>&lt;</mo><mi>w</mi><mo>&gt;</mo></mrow></msub><mo>⁢</mo><mi mathvariant="normal">#</mi></mrow></mrow></math>

</div>
<div id="alg2.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">18:</span></span>     <span class="ltx_text ltx_font_bold">for all</span> character <math id="alg2.l18.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> in TRY such that <math id="alg2.l18.m2" class="ltx_Math" alttext="c!=d" display="inline"><mrow><mrow><mi>c</mi><mo lspace="0pt" rspace="3.5pt">!</mo></mrow><mo>=</mo><mi>d</mi></mrow></math> <span class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg2.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>        <math id="alg2.l19.m1" class="ltx_Math" alttext="Lex_{TRY}\leftarrow Lex_{TRY}\cup c:d_{&lt;w&gt;}\#" display="inline"><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>T</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>←</mo><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>T</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>Y</mi></mrow></msub></mrow><mo>∪</mo><mi>c</mi></mrow></mrow><mo>:</mo><mrow><msub><mi>d</mi><mrow><mo>&lt;</mo><mi>w</mi><mo>&gt;</mo></mrow></msub><mo>⁢</mo><mi mathvariant="normal">#</mi></mrow></mrow></math>
{for swap: replace <math id="alg2.l19.m2" class="ltx_Math" alttext="\#" display="inline"><mi mathvariant="normal">#</mi></math> with <math id="alg2.l19.m3" class="ltx_Math" alttext="cd" display="inline"><mrow><mi>c</mi><mo>⁢</mo><mi>d</mi></mrow></math> and add <math id="alg2.l19.m4" class="ltx_Math" alttext="Lex_{cd}\cup d:c_{&lt;0&gt;}\#" display="inline"><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>c</mi><mo>⁢</mo><mi>d</mi></mrow></msub></mrow><mo>∪</mo><mi>d</mi></mrow><mo>:</mo><mrow><msub><mi>c</mi><mrow><mo>&lt;</mo><mn>0</mn><mo>&gt;</mo></mrow></msub><mo>⁢</mo><mi mathvariant="normal">#</mi></mrow></mrow></math>}

</div>
<div id="alg2.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"><span class="ltx_text" style="font-size:80%;">20:</span></span>     <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg2.l21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>

</div>
</div>
</figure>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_listing ltx_lst_numbers_left ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgIExFWElDT04gSFVOU1BFTExfZXJyb3Jfcm9vdCB8LVxsYWJlbHtsZXhjZXJyb3Jyb290c3Rh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%0AeGNlcnJvcnJlcGVuZH0tfAo=%0A">⬇</a></div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">1</span><span class="ltx_text ltx_lst_space">    </span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_error_root</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>&lt;<span class="ltx_text ltx_lst_space"> </span>?<span class="ltx_text ltx_lst_space"> </span>&gt;<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_error_root</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">3</span><span class="ltx_text ltx_lst_identifier">HUNSPELL_KEY</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">HUNSPELL_REP</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>100”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">5</span><span class="ltx_text ltx_lst_identifier">HUNSPELL_TRY</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>1000”<span class="ltx_text ltx_lst_space"> </span>;<span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">7</span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>&lt;<span class="ltx_text ltx_lst_space"> </span>?<span class="ltx_text ltx_lst_space"> </span>&gt;<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">9</span>#<span class="ltx_text ltx_lst_space"> </span>;<span class="ltx_text ltx_lst_space">  </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">11</span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_KEY</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ö:ü<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">13</span>ö:ó<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ü:ö<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">15</span>ü:ó<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ó:ö<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">17</span>ó:ü<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>0”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>!<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">same</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">other</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">parts</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">19</span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_TRY</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">21</span>í:0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>1”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>0:í<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>1”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">23</span>í:ó<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>2”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ó:í<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>2”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">25</span>ó:0<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>2”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>0:ó<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>2”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">27</span>!<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">same</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">rest</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">of</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">the</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">alphabet</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">29</span><span class="ltx_text ltx_lst_identifier">LEXICON</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_REP</span><span class="ltx_text ltx_lst_space"> </span>
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>í:<span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>1”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">31</span><span class="ltx_text ltx_lst_identifier">i</span>:í<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>2”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>ó:<span class="ltx_text ltx_lst_identifier">o</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>3”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">33</span><span class="ltx_text ltx_lst_identifier">oliere</span>:<span class="ltx_text ltx_lst_identifier">oli</span>è<span class="ltx_text ltx_lst_identifier">re</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>4”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">cc</span>:<span class="ltx_text ltx_lst_identifier">gysz</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>5”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">35</span><span class="ltx_text ltx_lst_identifier">cs</span>:<span class="ltx_text ltx_lst_identifier">ts</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>6”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span><span class="ltx_text ltx_lst_identifier">cs</span>:<span class="ltx_text ltx_lst_identifier">ds</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>7”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing">37</span><span class="ltx_text ltx_lst_identifier">ccs</span>:<span class="ltx_text ltx_lst_identifier">ts</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">HUNSPELL_errret</span><span class="ltx_text ltx_lst_space"> </span>”<span class="ltx_text ltx_lst_identifier">weight</span>:<span class="ltx_text ltx_lst_space"> </span>8”<span class="ltx_text ltx_lst_space"> </span>;
</div>
<div class="ltx_listingline">
<span class="ltx_tag ltx_tag_listing"></span>!<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">same</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">rest</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">of</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">REP</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">pairs</span>…<span class="ltx_text ltx_lst_space"> </span>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Converted error models from aff file</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Weighting Finite-State Dictionaries with Wikipedia</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p">Finite-state automata can be weighted simply by using finite-state composition.
For corpus based weighting, the automata containing weighted language model
simply encodes a probability of a token appearing in the corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="Finite-state spell-checking with weighted language and error models" class="ltx_ref">8</a>]</cite>.
The weights are formulated as penalty values belonging to the weighted semiring
using formula of <math id="S4.SS3.p1.m1" class="ltx_Math" alttext="-\log\frac{f}{CS}" display="inline"><mrow><mo>-</mo><mrow><mi>log</mi><mo>⁡</mo><mfrac><mi>f</mi><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow></mfrac></mrow></mrow></math> where <math id="S4.SS3.p1.m2" class="ltx_Math" alttext="f" display="inline"><mi>f</mi></math> is the frequency of token, and
<math id="S4.SS3.p1.m3" class="ltx_Math" alttext="CS" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow></math> the size of corpus in tokens. For tokens not appearing in the corpus, a
maximum weight of <math id="S4.SS3.p1.m4" class="ltx_Math" alttext="-\log\frac{1}{CS+1}" display="inline"><mrow><mo>-</mo><mrow><mi>log</mi><mo>⁡</mo><mfrac><mn>1</mn><mrow><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow><mo>+</mo><mn>1</mn></mrow></mfrac></mrow></mrow></math> is used to ensure they will be suggested
last by the error correction mechanism.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p class="ltx_p">Since also the error model is weighted, the
weights need to be scaled so that combining them under semiring’s addition
operation will produce reasonable results. In our experiment we have opted to
scale the weights of the error model so that the weight of making one error is
always greater than the back-off weight in the unigram weighting model. Using
this scaling ensures that the error model has precedence over the probability
data learned from the dictionary, which may only fine-tune the results in cases
where multiple choices are at the same error distance using the error model.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p class="ltx_p">The tokens are extracted from the wikipedia using dictionary transducer and
tokenizing analysis algorithm<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">garrido-alenda/2002</span>]</cite>. This algorithm uses
the dictionary automaton to extract tokens that appear in the dictionary from
the wikipedia data. The rest of the tokens are formed from contiguous runs of
other dictionary characters which did not result in dictionary word-form. From
this set, the correct tokens are turned into weighted suffix tree automaton
using the <math id="S4.SS3.p3.m1" class="ltx_Math" alttext="-\log\frac{f}{CS}" display="inline"><mrow><mo>-</mo><mrow><mi>log</mi><mo>⁡</mo><mfrac><mi>f</mi><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow></mfrac></mrow></mrow></math> formula for the weights, and this is unioned with
a version of original dictionary whose final weights have been set to the
maximum weight, <math id="S4.SS3.p3.m2" class="ltx_Math" alttext="-\log\frac{1}{CS+1}" display="inline"><mrow><mo>-</mo><mrow><mi>log</mi><mo>⁡</mo><mfrac><mn>1</mn><mrow><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi></mrow><mo>+</mo><mn>1</mn></mrow></mfrac></mrow></mrow></math>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Tests and Evaluation</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">We have implemented the spell-checkers and their error models as finite-state
transducers using program code and scripts with a Makefile. To test the code,
we have converted 42 hunspell dictionaries from various language families. They
consist of the dictionaries that were accessible from the aforementioned web
sites at the time of writing. The Table <a href="#S5.T1" title="Table 1 ‣ 5 Tests and Evaluation ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> gives an
overview of the sizes of the compiled automata. The size is given in binary
multiples of bytes as reported by <span class="ltx_text ltx_font_typewriter">ls -hl</span>. In the
Table <a href="#S5.T1" title="Table 1 ‣ 5 Tests and Evaluation ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we also give the number of roots in the
dictionary file and the affixes in affix file. These numbers should also help
with identifying the version of the dictionary, since there are multiple
different versions available in the downloads.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Compiled Hunspell automata sizes</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Language</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Dictionary</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Roots</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Affixes</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_tt">Portugese (Brazil)</td>
<td class="ltx_td ltx_align_center ltx_border_tt">14 MiB</td>
<td class="ltx_td ltx_align_center ltx_border_tt">307,199</td>
<td class="ltx_td ltx_align_center ltx_border_tt">25,434</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Polish</td>
<td class="ltx_td ltx_align_center">14 MiB</td>
<td class="ltx_td ltx_align_center">277,964</td>
<td class="ltx_td ltx_align_center">6,909</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Czech</td>
<td class="ltx_td ltx_align_center">12 MiB</td>
<td class="ltx_td ltx_align_center">302,542</td>
<td class="ltx_td ltx_align_center">2,492</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Hungarian</td>
<td class="ltx_td ltx_align_center">9.7 MiB</td>
<td class="ltx_td ltx_align_center">86,230</td>
<td class="ltx_td ltx_align_center">22,991</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Northern Sámi</td>
<td class="ltx_td ltx_align_center">8.1 MiB</td>
<td class="ltx_td ltx_align_center">527,474</td>
<td class="ltx_td ltx_align_center">370,982</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Slovak</td>
<td class="ltx_td ltx_align_center">7.1 MiB</td>
<td class="ltx_td ltx_align_center">175,465</td>
<td class="ltx_td ltx_align_center">2,223</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Dutch</td>
<td class="ltx_td ltx_align_center">6.7 MiB</td>
<td class="ltx_td ltx_align_center">158,874</td>
<td class="ltx_td ltx_align_center">90</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Gascon</td>
<td class="ltx_td ltx_align_center">5.1 MiB</td>
<td class="ltx_td ltx_align_center">2,098,768</td>
<td class="ltx_td ltx_align_center">110</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Afrikaans</td>
<td class="ltx_td ltx_align_center">5.0 MiB</td>
<td class="ltx_td ltx_align_center">125,473</td>
<td class="ltx_td ltx_align_center">48</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Icelandic</td>
<td class="ltx_td ltx_align_center">5.0 MiB</td>
<td class="ltx_td ltx_align_center">222087</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Greek</td>
<td class="ltx_td ltx_align_center">4.3 MiB</td>
<td class="ltx_td ltx_align_center">574,961</td>
<td class="ltx_td ltx_align_center">126</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Italian</td>
<td class="ltx_td ltx_align_center">3.8 MiB</td>
<td class="ltx_td ltx_align_center">95,194</td>
<td class="ltx_td ltx_align_center">2,687</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Gujarati</td>
<td class="ltx_td ltx_align_center">3.7 MiB</td>
<td class="ltx_td ltx_align_center">168,956</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Lithuanian</td>
<td class="ltx_td ltx_align_center">3.6 MiB</td>
<td class="ltx_td ltx_align_center">95,944</td>
<td class="ltx_td ltx_align_center">4,024</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">English (Great Britain)</td>
<td class="ltx_td ltx_align_center">3.5 MiB</td>
<td class="ltx_td ltx_align_center">46,304</td>
<td class="ltx_td ltx_align_center">1,011</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">German</td>
<td class="ltx_td ltx_align_center">3.3 MiB</td>
<td class="ltx_td ltx_align_center">70,862</td>
<td class="ltx_td ltx_align_center">348</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Croatian</td>
<td class="ltx_td ltx_align_center">3.3 MiB</td>
<td class="ltx_td ltx_align_center">215,917</td>
<td class="ltx_td ltx_align_center">64</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Spanish</td>
<td class="ltx_td ltx_align_center">3.2 MiB</td>
<td class="ltx_td ltx_align_center">76,441</td>
<td class="ltx_td ltx_align_center">6,773</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Catalan</td>
<td class="ltx_td ltx_align_center">3.2 MiB</td>
<td class="ltx_td ltx_align_center">94,868</td>
<td class="ltx_td ltx_align_center">996</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Slovenian</td>
<td class="ltx_td ltx_align_center">2.9 MiB</td>
<td class="ltx_td ltx_align_center">246,857</td>
<td class="ltx_td ltx_align_center">484</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Faeroese</td>
<td class="ltx_td ltx_align_center">2.8 MiB</td>
<td class="ltx_td ltx_align_center">108,632</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">French</td>
<td class="ltx_td ltx_align_center">2.8 MiB</td>
<td class="ltx_td ltx_align_center">91,582</td>
<td class="ltx_td ltx_align_center">507</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Swedish</td>
<td class="ltx_td ltx_align_center">2.5 MiB</td>
<td class="ltx_td ltx_align_center">64,475</td>
<td class="ltx_td ltx_align_center">330</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">English (U.S.)</td>
<td class="ltx_td ltx_align_center">2.5 MiB</td>
<td class="ltx_td ltx_align_center">62,135</td>
<td class="ltx_td ltx_align_center">41</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Estonian</td>
<td class="ltx_td ltx_align_center">2.4 MiB</td>
<td class="ltx_td ltx_align_center">282,174</td>
<td class="ltx_td ltx_align_center">9,242</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Portugese (Portugal)</td>
<td class="ltx_td ltx_align_center">2 MiB</td>
<td class="ltx_td ltx_align_center">40.811</td>
<td class="ltx_td ltx_align_center">913</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Irish</td>
<td class="ltx_td ltx_align_center">1.8 MiB</td>
<td class="ltx_td ltx_align_center">91,106</td>
<td class="ltx_td ltx_align_center">240</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Friulian</td>
<td class="ltx_td ltx_align_center">1.7 MiB</td>
<td class="ltx_td ltx_align_center">36,321</td>
<td class="ltx_td ltx_align_center">664</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Nepalese</td>
<td class="ltx_td ltx_align_center">1.7 MiB</td>
<td class="ltx_td ltx_align_center">39,925</td>
<td class="ltx_td ltx_align_center">502</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Thai</td>
<td class="ltx_td ltx_align_center">1.7 MiB</td>
<td class="ltx_td ltx_align_center">38,870</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Esperanto</td>
<td class="ltx_td ltx_align_center">1.5 MiB</td>
<td class="ltx_td ltx_align_center">19,343</td>
<td class="ltx_td ltx_align_center">2,338</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Hebrew</td>
<td class="ltx_td ltx_align_center">1.4 MiB</td>
<td class="ltx_td ltx_align_center">329237</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Bengali</td>
<td class="ltx_td ltx_align_center">1.3 MiB</td>
<td class="ltx_td ltx_align_center">110,751</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Frisian</td>
<td class="ltx_td ltx_align_center">1.2 MiB</td>
<td class="ltx_td ltx_align_center">24,973</td>
<td class="ltx_td ltx_align_center">73</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Interlingua</td>
<td class="ltx_td ltx_align_center">1.1 MiB</td>
<td class="ltx_td ltx_align_center">26850</td>
<td class="ltx_td ltx_align_center">54</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Persian</td>
<td class="ltx_td ltx_align_center">791 KiB</td>
<td class="ltx_td ltx_align_center">332,555</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Indonesian</td>
<td class="ltx_td ltx_align_center">765 KiB</td>
<td class="ltx_td ltx_align_center">23,419</td>
<td class="ltx_td ltx_align_center">17</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Azerbaijani</td>
<td class="ltx_td ltx_align_center">489 KiB</td>
<td class="ltx_td ltx_align_center">19,132</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Hindi</td>
<td class="ltx_td ltx_align_center">484 KiB</td>
<td class="ltx_td ltx_align_center">15,991</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Amharic</td>
<td class="ltx_td ltx_align_center">333 KiB</td>
<td class="ltx_td ltx_align_center">13,741</td>
<td class="ltx_td ltx_align_center">4</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Chichewa</td>
<td class="ltx_td ltx_align_center">209 KiB</td>
<td class="ltx_td ltx_align_center">5,779</td>
<td class="ltx_td ltx_align_center">0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b">Kashubian</td>
<td class="ltx_td ltx_align_center ltx_border_b">191 KiB</td>
<td class="ltx_td ltx_align_center ltx_border_b">5,111</td>
<td class="ltx_td ltx_align_center ltx_border_b">0</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p">To test the converted spell-checking dictionaries and error models, we pickedn
10 dictionaries of varying size and features. For spelling material we
created sets of 1000 spelling errors automatically, by introducing spelling
errors to the tokens of Wikipedia data. The errors have been made by a python
script implementing the edit distance type of errors to the words with
likelihood of 1/33 per character. The words which didn’t receive any automatic
mispellings were not included in the test set, but words were spelling errors
introduced led to another word form of the language were retained.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p class="ltx_p">The table <a href="#S5.T3" title="Table 3 ‣ 5 Tests and Evaluation ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes the spelling suggestions made
by original hunspell algorithms, and our finite-state automata. Four variants
of finite-state automata combinations were tested; one allowing for two
hunspell errors without any weighting, one with wikipedia frequencies in
dictionary and one with weighted error model allowing up to four of converted
hunspell errors. The hunspell results were obtained by <span class="ltx_text ltx_font_typewriter">hunspell -1 -d
$LL &lt; misspelings</span>, and automata were applied using experimental HFST tool
<span class="ltx_text ltx_font_typewriter">hfst-ospell error-model dictionary</span>. In the table, the column C is for
correct spelling results, that are foyund in the dictionary—in this case,
false positives. The colums 1, 2—4 and L show numbers of correct results
showing as first, other top four, or lower suggestions. The column M contains
misses, where correct suggestion was not given at all.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Suggestion algorithm results</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Language</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5"><span class="ltx_text ltx_font_bold" style="font-size:70%;">Hunspell</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5"><span class="ltx_text ltx_font_bold" style="font-size:70%;">FST</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5"><span class="ltx_text ltx_font_bold" style="font-size:70%;">FST + Unigrams</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5"><span class="ltx_text ltx_font_bold" style="font-size:70%;">FST + 4 errors</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">C</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">2—4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">M</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">C</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">2—4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">M</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">C</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">2—4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">M</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">C</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">2—4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column"><span class="ltx_text" style="font-size:70%;">M</span></th>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">English (American)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">46</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">768</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">116</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">20</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">50</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">20</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">515</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">203</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">121</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">141</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">20</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">575</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">158</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">106</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text" style="font-size:70%;">141</span></td>
<td class="ltx_td ltx_border_tt"></td>
<td class="ltx_td ltx_border_tt"></td>
<td class="ltx_td ltx_border_tt"></td>
<td class="ltx_td ltx_border_tt"></td>
<td class="ltx_td ltx_border_tt"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">Occitan</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">0</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">233</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">20</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">2</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">25</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">0</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">236</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">19</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">0</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">25</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">0</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">239</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">20</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">2</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">19</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">Kurdish</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">1</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">238</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">27</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">3</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">141</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">1</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">237</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">27</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">4</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">141</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">1</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">238</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">30</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">4</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">137</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">Interlingua</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">7</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">570</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">122</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">27</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">274</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">7</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">790</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">107</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">15</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">81</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">Polish</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">German</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">9</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">636</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">77</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">22</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">256</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">Hungarian</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">6</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">424</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">30</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">8</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">482</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">French</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="font-size:70%;">Slovak</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="font-size:70%;">Icelandic</span></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.p4" class="ltx_para">
<p class="ltx_p">The time requirements of each system was also briefly teste using standard
Unix <code class="ltx_verbatim ltx_font_typewriter">time(1)</code> tool to measure the time of correcting the 1000
mispelled strings used for testing precision and recall of the systems
previously. The times were measured on application server provided by
centre of scientific computation Finland with 8 quad-core processors
AMD 8360 and 512 GiB of RAM memory available
<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><a href="http://www.csc.fi/english/pages/hippu%5C_guide/introduction/overview/index%5C_html/?searchterm=hippu" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.csc.fi/english/pages/hippu\_guide/introduction/overview/index\_html/?searchterm=hippu</a></span></span></span>.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p class="ltx_p">The tests reveal that the weighting of dictionary and error model give no
significant hit to the performance of spell checking and correction, whereas
extending the search space by doubling the error model will sharply decrease the
running time.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Suggestion algorithm speed</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Language</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Hunspell</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">FST</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">FST + Unigrams</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">FST + 4 errors</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_tt">English (American)</td>
<td class="ltx_td ltx_align_center ltx_border_tt">56.5 s</td>
<td class="ltx_td ltx_align_center ltx_border_tt">15.5 s</td>
<td class="ltx_td ltx_align_center ltx_border_tt">16.1 s</td>
<td class="ltx_td ltx_border_tt"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Occitan</td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center">0.1 s</td>
<td class="ltx_td ltx_align_center">0.1 s</td>
<td class="ltx_td ltx_align_center">86.3 s</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Kurdish</td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center">1.1 s</td>
<td class="ltx_td ltx_align_center">1.1 s</td>
<td class="ltx_td ltx_align_center">103.2 s</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Interlingua</td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center">2.9 s</td>
<td class="ltx_td ltx_align_center">4.9 s</td>
<td class="ltx_td ltx_align_center">196.3 s</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Polish</td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"> German</td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Hungarian</td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">French</td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">Slovak</td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b">Icelandic</td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
<td class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">We have demonstrated a method and created the software to convert legacy
spell-checker and hyphenation data to a more general framework of
finite-state automata and used it in a real-life application.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">The authors would like to thank Miikka Silfverberg, Sam Hardwick and Brian
Croom and others in the HFST research team for contributions to research tools
and useful discussions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib9" class="ltx_bibitem ltx_bib_book">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. R. Beesley and L. Karttunen</span><span class="ltx_text ltx_bib_year"> (2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Finite state morphology</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">CSLI publications</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 978-1575864341</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p2" title="2 Definitions ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. R. Beesley</span><span class="ltx_text ltx_bib_year"> (1998)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Constraining separated morphotactic dependencies in finite-state grammars</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Morristown, NJ, USA</span>, <span class="ltx_text ltx_bib_pages"> pp. 118–127</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 975-7679-34-8</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p1" title="4.1 Hunspell dictionary conversion ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem ltx_bib_proceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_editor">A. F. Gelbukh (Ed.)</span><span class="ltx_text ltx_bib_year"> (2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Computational linguistics and intelligent text processing, 9th international conference, cicling 2008, haifa, israel, february 17-23, 2008, proceedings</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">Springer</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#bib.bib134" title="Real-word spelling correction with trigrams: a reconsideration of the mays, damerau, and mercer model" class="ltx_ref">9</a>.
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem ltx_bib_thesis">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Koskenniemi</span><span class="ltx_text ltx_bib_year"> (1983)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Two-level morphology: a general computational model for word-form recognition and production</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Ph.D. Thesis</span>, <span class="ltx_text ltx_bib_publisher">University of Helsinki</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.ling.helsinki.fi/koskenni/doc/Two-LevelMorphology.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p2" title="4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. LindÃ©n, M. Silfverberg and T. Pirinen</span><span class="ltx_text ltx_bib_year"> (2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">HFST tools for morphology—an efficient open-source package for construction of morphological analyzers</span>.
</span>
<span class="ltx_bibblock">See <span class="ltx_text ltx_bib_crossref"><cite class="ltx_cite"><a href="#bib.bib121" title="Workshop on systems and frameworks for computational morphology, sfcm 2009, zÃ¼rich, switzerland, september 2009, proceedings" class="ltx_ref">Workshop on systems and frameworks for computational morphology, sfcm 2009, zÃ¼rich, switzerland, september 2009, proceedings, Mahlow and Piotrowski</a></cite></span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 28–47</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p2" title="4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem ltx_bib_proceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_editor">C. Mahlow and M. Piotrowski (Eds.)</span><span class="ltx_text ltx_bib_year"> (2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Workshop on systems and frameworks for computational morphology, sfcm 2009, zÃ¼rich, switzerland, september 2009, proceedings</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">Lecture Notes in Computer Science</span>, Vol. <span class="ltx_text ltx_bib_volume">41</span>,  <span class="ltx_text ltx_bib_publisher">Springer</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 978-3-642-04130-3</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#bib.bib70" title="HFST tools for morphology—an efficient open-source package for construction of morphological analyzers" class="ltx_ref">5</a>.
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem ltx_bib_misc">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Mohri and M. Riley</span><span class="ltx_text ltx_bib_year"> (2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">An efficient algorithm for the n-best-strings problem</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Definitions ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. A. Pirinen and K. LindÃ©n</span><span class="ltx_text ltx_bib_year"> (2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Finite-state spell-checking with weighted language and error models</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the Seventh SaLTMiL workshop on creation and use of basic lexical resources for less-resourced languagages</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Valletta, Malta</span>, <span class="ltx_text ltx_bib_pages"> pp. 13–18</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://siuc01.si.ehu.es/%7Ejipsagak/SALTMIL2010%5C_Proceedings.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.p3" title="2 Definitions ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S4.SS2.p4" title="4.2 Hunspell Error Models ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>,
<a href="#S4.SS3.p1" title="4.3 Weighting Finite-State Dictionaries with Wikipedia ‣ 4 Methods ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. A. Wilcox-O’Hearn, G. Hirst and A. Budanitsky</span><span class="ltx_text ltx_bib_year"> (2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Real-word spelling correction with trigrams: a reconsideration of the mays, damerau, and mercer model</span>.
</span>
<span class="ltx_bibblock">See <span class="ltx_text ltx_bib_crossref"><cite class="ltx_cite"><a href="#bib.bib27" title="Computational linguistics and intelligent text processing, 9th international conference, cicling 2008, haifa, israel, february 17-23, 2008, proceedings" class="ltx_ref">Computational linguistics and intelligent text processing, 9th international conference, cicling 2008, haifa, israel, february 17-23, 2008, proceedings, Gelbukh</a></cite></span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 605–616</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ Creating and Weighting Hunspell Dictionaries as Finite-State Automata \footnotepubrightsThis journal article was originally published in investigationes linguisticae http://inveling.amu.edu.pl/index.php?page=issues&amp;vol=21." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 29 12:46:31 2017 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>
